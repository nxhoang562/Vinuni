{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb \n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# import argparse\n",
    "import sys\n",
    "import torch\n",
    "import yaml\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "\n",
    "from ae_dataset import make_dataset as ae_make_dataset\n",
    "from ae_dataset import make_dataloader as ae_make_dataloader\n",
    "\n",
    "from est_dataset import make_dataset as est_make_dataset\n",
    "from est_dataset import make_dataloader as est_make_dataloader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from metrics import compute_pck_pckh, calculate_error\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "\n",
    "# sys.path.append(\"/home/nxhoang/Work/HPE\")\n",
    "# # from src.denoise.model import AutoEncoder\n",
    "# # from src.denoise.train import Trainer as Denoise_Trainer\n",
    "# # from src.model.Denoise_Fdcnn import CombinedModel\n",
    "# # from src.keypoint_detection.models.fdcnn import CNN\n",
    "# # from src.keypoint_detection.trainer import Trainer as Estimastor_Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other_config = {'modality': 'wifi-csi',\n",
    "#                         'protocol': 'protocol1',\n",
    "#                         'data_unit': 'frame',\n",
    "#                         'random_split': {'ratio': 0.8,\n",
    "#                                          'random_seed': 42,\n",
    "#                                          'train_dataset': {'split': 'training',\n",
    "#                                                             'scenes': 'None',\n",
    "#                                                             'subjects': 'None',\n",
    "#                                                           'actions': 'all'},\n",
    "#                                           'val_dataset': {'split': 'validation',\n",
    "#                                                           'scenes': 'None',\n",
    "#                                                           'subjects': 'None',\n",
    "#                                                           'actions': 'all'}},\n",
    "#                         'cross_scene_split': {'train_dataset': {'split': 'training',\n",
    "#                                               'scenes': ['E01', 'E02', 'E03'],\n",
    "#                                               'subjects': 'None',\n",
    "#                                               'actions': 'all'},\n",
    "#                                               'val_dataset': {'split': 'validation',\n",
    "#                                                               'scenes': ['E04'],\n",
    "#                                                               'subjects': 'None',\n",
    "#                                                               'actions': 'all'}},\n",
    "#                         'cross_subject_split': {'train_dataset': {'split': 'training',\n",
    "#                                                                   'scenes': 'None',\n",
    "#                                                                   'subjects': ['S01','S02','S03','S04','S06','S07','S08','S09','S11','S12','S13','S14','S16','S17','S18','S19','S21','S22','S23','S24','S26','S27','S28','S29','S31','S32','S33','S34','S36','S37','S38','S39'],\n",
    "#                                                                   'actions': 'all'},\n",
    "#                                                 'val_dataset': {'split': 'validation',\n",
    "#                                                                 'scenes': 'None',\n",
    "#                                                                 'subjects': ['S05', 'S10', 'S15', 'S20', 'S25', 'S30', 'S35', 'S40'],\n",
    "#                                                                 'actions': 'all'}},\n",
    "#                         'manual_split': {'train_dataset': {'split': 'training',\n",
    "#                                                            'scenes': 'None',\n",
    "#                                                            'subjects': ['S01','S02','S03','S04','S05','S06','S07','S08','S09','S10','S11','S12','S13','S14','S15','S16','S17','S18','S19','S20','S21','S22','S23','S24','S25','S26','S27','S28','S29','S30','S31','S32','S33','S34','S35','S36','S37','S38','S39','S40'],\n",
    "#                                                            'actions': ['A01','A02','A03','A04','A05','A06','A07','A08','A09','A10','A11','A12','A13','A14','A15','A16','A17','A18','A19','A20','A21']},\n",
    "#                                           'val_dataset': {'split': 'validation',\n",
    "#                                                           'scenes': 'None',\n",
    "#                                                           'subjects': ['S01','S02','S03','S04','S05','S06','S07','S08','S09','S10','S11','S12','S13','S14','S15','S16','S17','S18','S19','S20','S21','S22','S23','S24','S25','S26','S27','S28','S29','S30','S31','S32','S33','S34','S35','S36','S37','S38','S39','S40'],\n",
    "#                                                           'actions': ['A22', 'A23', 'A24', 'A25', 'A26', 'A27']}},\n",
    "#                         'split_to_use': 'random_split',\n",
    "#                         'init_rand_seed': 0,\n",
    "#                         'data_root': '/home/nxhoang/Work/HPE-VinUni/Data',\n",
    "#                         'AE_checkpoint': '/home/nxhoang/Work/HPE-VinUni/src/model/checkpoints/AE_model_best.pth',\n",
    "#                         'combined_checkpoint': '/home/nxhoang/Work/HPE-VinUni/src/model/checkpoints/combined_model_best.pth'}\n",
    "\n",
    "# est_train_dataset, est_test_dataset = est_make_dataset(other_config[\"data_root\"], other_config)\n",
    "# rng_generator1 = torch.manual_seed(other_config['init_rand_seed'])\n",
    "# train_loader1 = est_make_dataloader(est_train_dataset, is_training=True, generator=rng_generator1,\n",
    "#                                                  batch_size = 32)\n",
    "# val_data1, test_data1 = train_test_split(est_test_dataset, test_size=0.5, random_state=41)\n",
    "# val_loader1 = est_make_dataloader(val_data1, is_training=False, generator=rng_generator1,\n",
    "#                                                batch_size = 32)\n",
    "# test_loader1 = est_make_dataloader(test_data1, is_training=False, generator=rng_generator1,\n",
    "#                                                 batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some codes are adopted from cite dynamic cnn \n",
    "\n",
    "class Dynamic_conv2d(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, bias=False, n_basis_kernels=4,\n",
    "                 temperature=31, pool_dim='freq'):\n",
    "        super(Dynamic_conv2d, self).__init__()\n",
    "\n",
    "        self.in_planes = in_planes\n",
    "        self.out_planes = out_planes\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.pool_dim = pool_dim\n",
    "\n",
    "        self.n_basis_kernels = n_basis_kernels\n",
    "        self.attention = attention2d(in_planes, self.kernel_size, self.stride, self.padding, n_basis_kernels,\n",
    "                                     temperature, pool_dim)\n",
    "\n",
    "        self.weight = nn.Parameter(torch.randn(n_basis_kernels, out_planes, in_planes, self.kernel_size, self.kernel_size),\n",
    "                                   requires_grad=True)\n",
    "\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(n_basis_kernels, out_planes))\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        for i in range(self.n_basis_kernels):\n",
    "            nn.init.kaiming_normal_(self.weight[i])\n",
    "\n",
    "    def forward(self, x): #x size : [bs, in_chan, frames, freqs]   -> new: [bs, in_chan, freqs, frames]\n",
    "        if self.pool_dim in ['freq', 'chan']:\n",
    "            # softmax_attention = self.attention(x).unsqueeze(2).unsqueeze(4)    # size : [bs, n_ker, 1, frames, 1]\n",
    "            softmax_attention = self.attention(x).unsqueeze(2).unsqueeze(3)    # size : [bs, n_ker, 1,1,frames]\n",
    "        elif self.pool_dim == 'time':\n",
    "            softmax_attention = self.attention(x).unsqueeze(2).unsqueeze(4)    # size : [bs, n_ker, 1, freqs, 1]\n",
    "        elif self.pool_dim == 'both':\n",
    "            softmax_attention = self.attention(x).unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)    # size : [bs, n_ker, 1, 1, 1]\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        aggregate_weight = self.weight.view(-1, self.in_planes, self.kernel_size, self.kernel_size) # size : [n_ker * out_chan, in_chan]\n",
    "\n",
    "        if self.bias is not None:\n",
    "            aggregate_bias = self.bias.view(-1)\n",
    "            output = F.conv2d(x, weight=aggregate_weight, bias=aggregate_bias, stride=self.stride, padding=self.padding)\n",
    "        else:\n",
    "            output = F.conv2d(x, weight=aggregate_weight, bias=None, stride=self.stride, padding=self.padding)\n",
    "            # output size : [bs, n_ker * out_chan, frames, freqs]\n",
    "\n",
    "        output = output.view(batch_size, self.n_basis_kernels, self.out_planes, output.size(-2), output.size(-1))\n",
    "        # output size : [bs, n_ker, out_chan, frames, freqs]\n",
    "\n",
    "        if self.pool_dim in ['freq', 'chan']:\n",
    "            assert softmax_attention.shape[-1] == output.shape[-1]\n",
    "        elif self.pool_dim == 'time':\n",
    "            assert softmax_attention.shape[-2] == output.shape[-2]\n",
    "\n",
    "        output = torch.sum(output * softmax_attention, dim=1)  # output size : [bs, out_chan, frames, freqs]\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class attention2d(nn.Module):\n",
    "    def __init__(self, in_planes, kernel_size, stride, padding, n_basis_kernels, temperature, pool_dim):\n",
    "        super(attention2d, self).__init__()\n",
    "        self.pool_dim = pool_dim\n",
    "        self.temperature = temperature\n",
    "\n",
    "        hidden_planes = int(in_planes / 4)\n",
    "\n",
    "        if hidden_planes < 4:\n",
    "            hidden_planes = 4\n",
    "\n",
    "        if not pool_dim == 'both':\n",
    "            self.conv1d1 = nn.Conv1d(in_planes, hidden_planes, kernel_size, stride=stride, padding=padding, bias=False)\n",
    "            self.bn = nn.BatchNorm1d(hidden_planes)\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "            self.conv1d2 = nn.Conv1d(hidden_planes, n_basis_kernels, 1, bias=True)\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv1d):\n",
    "                    nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                    if m.bias is not None:\n",
    "                        nn.init.constant_(m.bias, 0)\n",
    "                if isinstance(m, nn.BatchNorm1d):\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "        else:\n",
    "            self.fc1 = nn.Linear(in_planes, hidden_planes)\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "            self.fc2 = nn.Linear(hidden_planes, n_basis_kernels)\n",
    "\n",
    "\n",
    "    def forward(self, x): #CSI size : [bs, chan, freqs, frames] \n",
    "        if self.pool_dim == 'freq':\n",
    "            x = torch.mean(x, dim=2)  #x size : [bs, chan, frames] \n",
    "        elif self.pool_dim == 'time':\n",
    "            x = torch.mean(x, dim=3)  #x size : [bs, chan, freqs]\n",
    "        elif self.pool_dim == 'both':\n",
    "            # x = torch.mean(torch.mean(x, dim=2), dim=1)  #x size : [bs, chan]\n",
    "            x = F.adaptive_avg_pool2d(x, (1, 1)).squeeze(-1).squeeze(-1)\n",
    "        elif self.pool_dim == 'chan':\n",
    "            x = torch.mean(x, dim=1)  #x size : [bs, freqs, frames]\n",
    "\n",
    "        if not self.pool_dim == 'both':\n",
    "            x = self.conv1d1(x)               #x size : [bs, hid_chan, frames]\n",
    "            x = self.bn(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.conv1d2(x)               #x size : [bs, n_ker, frames]\n",
    "        else:\n",
    "            x = self.fc1(x)               #x size : [bs, hid_chan]\n",
    "            x = self.relu(x)\n",
    "            x = self.fc2(x)               #x size : [bs, n_ker]\n",
    "\n",
    "        return F.softmax(x / self.temperature, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DENOISER \n",
    "\n",
    "# Doi Batch Norm len truoc \n",
    "\n",
    "\n",
    "#d_hidden, dropout_ae\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, shape_data, n_kernels, kernel_size, maxpooling):\n",
    "        super().__init__()\n",
    "        self.shape_data = shape_data\n",
    "        self.n_kernels = n_kernels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.maxpooling = maxpooling \n",
    "\n",
    "      # input -> conv2d -> batchnorm -> maxpool2d ->conv2d -> batchnorm -> maxpool     \n",
    "       # layer1\n",
    "        self.conv1 = nn.Conv2d(\n",
    "                                in_channels=self.shape_data[0],\n",
    "                                out_channels=self.n_kernels[0],\n",
    "                                kernel_size=self.kernel_size[0],\n",
    "                                padding=1\n",
    "                               )\n",
    "        self.atv1 = nn.ReLU()\n",
    "        self.batchNorm1 = nn.BatchNorm2d(num_features=self.n_kernels[0])\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=self.maxpooling[0])     \n",
    "\n",
    "        # layer 2 \n",
    "        self.conv2 = nn.Conv2d(\n",
    "                                in_channels=self.n_kernels[0],\n",
    "                                out_channels=self.n_kernels[1],\n",
    "                                kernel_size=self.kernel_size[1],\n",
    "                                padding=1\n",
    "                                )\n",
    "        self.atv2 = nn.ReLU()\n",
    "        self.batchNorm2 = nn.BatchNorm2d(num_features=self.n_kernels[1])\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=self.maxpooling[1]) \n",
    "       \n",
    "        # height and weight of the output shape of conv1 \n",
    "        self.h_conv1 = int((self.shape_data[1] - self.kernel_size[0] + 3 )) # padding = 1\n",
    "        self.w_conv1 = int((self.shape_data[2] - self.kernel_size[0] + 3 ))      \n",
    "        \n",
    "        # output of max-pooling 1\n",
    "        self.h_pool1 = int((self.h_conv1 - self.maxpooling[0])/self.maxpooling[0] + 1)\n",
    "        # stride of max-pooling = maxpooling \n",
    "        self.w_pool1 = int((self.w_conv1 - self.maxpooling[0])/self.maxpooling[0] + 1) \n",
    "\n",
    "        # height and weight of the output shape of conv2 \n",
    "        self.h_conv2 = int(self.h_pool1 - self.kernel_size[1] + 3 ) # padding = 1\n",
    "        self.w_conv2 = int(self.w_pool1 - self.kernel_size[1] + 3 )      \n",
    "        \n",
    "        #output of max-pooling 2\n",
    "        self.h_pool2 = int((self.h_conv2 - self.maxpooling[1])/self.maxpooling[1] + 1)\n",
    "        self.w_pool2 = int((self.w_conv2 - self.maxpooling[1])/self.maxpooling[1] + 1) \n",
    "        \n",
    "        # # layer3\n",
    "        # self.conv3 = nn.Conv2d(in_channels=64, out_channels=3, kernel_size=3, padding=1)\n",
    "        # self.relu3 = nn.ReLU()\n",
    "        # self.pool3 = nn.MaxPool2d(kernel_size=2, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.pool1(self.batchNorm1(self.relu1(self.conv1(x))))\n",
    "        x = self.pool1(self.atv1(self.batchNorm1(self.conv1(x))))\n",
    "        x = self.pool2(self.atv2(self.batchNorm2(self.conv2(x))))\n",
    "\n",
    "       \n",
    "        # x = self.pool3(self.relu3(self.conv3(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, shape_data, n_kernels, kernel_size, maxpooling):\n",
    "        super().__init__()\n",
    "        self.shape_data = shape_data\n",
    "        self.n_kernels = n_kernels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.maxpooling = maxpooling \n",
    "\n",
    "        self.h_conv1 = int((self.shape_data[1] - self.kernel_size[0] + 3 ))\n",
    "        self.w_conv1 = int((self.shape_data[2] - self.kernel_size[0] + 3 ))   \n",
    "        self.h_pool1 = int((self.h_conv1 - self.maxpooling[0])/self.maxpooling[0] + 1)\n",
    "        self.w_pool1 = int((self.w_conv1 - self.maxpooling[0])/self.maxpooling[0] + 1) \n",
    "        \n",
    "        self.h_conv2 = int(self.h_pool1 - self.kernel_size[1] + 3 )\n",
    "        self.w_conv2 = int(self.w_pool1 - self.kernel_size[1] + 3)    \n",
    "        \n",
    "        self.h_pool2 = int((self.h_conv2 - self.maxpooling[1])/self.maxpooling[1] + 1)\n",
    "        self.w_pool2 = int((self.w_conv2 - self.maxpooling[1])/self.maxpooling[1] + 1) \n",
    "        \n",
    "        # Layer 3 ~ hidden layer\n",
    "        self.conv3 = nn.Conv2d(in_channels=self.n_kernels[1],\n",
    "                               out_channels=self.n_kernels[1],\n",
    "                               kernel_size=self.kernel_size[1],\n",
    "                               padding=1\n",
    "                               )\n",
    "        self.atv3 = nn.ReLU()\n",
    "        self.batchNorm3 = nn.BatchNorm2d(num_features=self.n_kernels[1])\n",
    "        # Upsampling:  desired_output_size = (32, 32)  # Upsample to 32x32\n",
    "        # upsample_layer = nn.Upsample(size=desired_output_size, mode='bilinear', align_corners=False)\n",
    "        self.up_pool3 = nn.Upsample(size =(self.h_conv2, self.w_conv2))\n",
    "\n",
    "        # Layer 4\n",
    "        self.conv4 = nn.Conv2d(in_channels=self.n_kernels[1],\n",
    "                               out_channels=self.n_kernels[0],\n",
    "                               kernel_size=self.kernel_size[0],\n",
    "                               padding=1 \n",
    "                                )\n",
    "        self.atv4 = nn.ReLU()\n",
    "        self.batchNorm4 = nn.BatchNorm2d(num_features=self.n_kernels[0])\n",
    "\n",
    "        self.up_pool4 = nn.Upsample(size = (self.h_conv1, self.w_conv1) )\n",
    "\n",
    "        # Layer 5  = output \n",
    "        self.conv5 = nn.Conv2d(in_channels=self.n_kernels[0],\n",
    "                               out_channels=self.shape_data[0],\n",
    "                               kernel_size=self.kernel_size[0],\n",
    "                               padding=1 \n",
    "                                )\n",
    "        self.atv5 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.up_pool3(self.batchNorm3(self.atv3(self.conv3(x))))\n",
    "        x = self.up_pool4(self.batchNorm4(self.atv4(self.conv4(x))))\n",
    "        x = self.atv5(self.conv5(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Denoiser(nn.Module):\n",
    "    def __init__(self, shape_data, n_kernels, kernel_size, maxpooling):\n",
    "        super().__init__()\n",
    "        self.shape_data = shape_data\n",
    "        self.n_kernels = n_kernels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.maxpooling = maxpooling\n",
    "        self.encoder = Encoder(self.shape_data,  self.n_kernels, self.kernel_size, self.maxpooling)\n",
    "        self.decoder = Decoder(self.shape_data,  self.n_kernels, self.kernel_size, self.maxpooling)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     test_model = AutoEncoder().to(\"cuda\")\n",
    "\n",
    "#     # ummary(test_model, input_size=(3, 32,136), batch_size=16, device=\"cuda\")\n",
    "#     pass\n",
    "\n",
    "# model = AutoEncoder(shape_data = (3,32,136), n_kernels = [64,4], kernel_size = [3,3], maxpooling = [2,2]).to(\"cuda\")\n",
    "model = Denoiser(shape_data = (3,136,32), n_kernels = [26,183], kernel_size = [3,3], maxpooling = [2,2]).to(\"cuda\")\n",
    "summary(model, (3, 136, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keypoint Estimator \n",
    "\n",
    "class Estimator(nn.Module):\n",
    "\n",
    "    \n",
    "    def __init__(self, shape_data,  \n",
    "                dropout = None,\n",
    "                kernel_size = [3, 3, 3,3,3],\n",
    "                n_kernels =[8, 8, 8,8,8],   \n",
    "                num_layers = 2,  \n",
    "                pad = [1, 1, 1,1,1], #fix la 1,k doi \n",
    "                stride = [1, 1, 1,1,1], #fix la 1, k doi                              \n",
    "                maxPooling = [3,3,2,2,2],\n",
    "                n_basis_kernels = 5, \n",
    "                temperature = 31,\n",
    "                d_linear = 128,\n",
    "                pool_dim = 'time'): \n",
    "        super(Estimator, self).__init__()\n",
    "        \n",
    "        self.num_layers  = num_layers # no. dcnn layers \n",
    "        # self.est_n_input_ch = est_n_input_ch  # no. channels\n",
    "        self.shape_data = shape_data\n",
    "        self.dropout = dropout\n",
    "        self.kernel_size = kernel_size # kernel size\n",
    "        self.n_kernels = n_kernels  # no. filters for each conv layer\n",
    "        self.pad = pad\n",
    "        self.stride = stride\n",
    "        self.maxPooling = maxPooling   # pooling dimensions for each poooling layers \n",
    "        self.n_basis_kernels = n_basis_kernels  # no. kernels\n",
    "        \n",
    "        self.temperature = temperature\n",
    "        self.pool_dim = pool_dim # dimension for pooling\n",
    "        self.d_linear = d_linear\n",
    "        # self.est_n_filt_last = est_kernel_size[-1]\n",
    "\n",
    "        \n",
    "        self.h_conv = [0]*self.num_layers\n",
    "        self.w_conv = [0]*self.num_layers\n",
    "        self.h_pool = [0]*self.num_layers\n",
    "        self.w_pool = [0]*self.num_layers\n",
    "        in_dim = [0]*self.num_layers\n",
    "        out_dim = [0]*self.num_layers\n",
    "\n",
    "\n",
    "        cnn = nn.Sequential()\n",
    "\n",
    "        def conv(i, dropout=None):\n",
    "            in_dim[i] = self.shape_data[0] if i == 0 else self.n_kernels[i-1] #kenh dau vao cua conv\n",
    "            out_dim[i] = self.n_kernels[i] #kenh dau ra cua conv \n",
    "\n",
    "            cnn.add_module( \"conv{0}\".format(i),\n",
    "                            Dynamic_conv2d(in_dim[i],\n",
    "                                           out_dim[i],\n",
    "                                           self.kernel_size[i],\n",
    "                                           self.stride[i],\n",
    "                                           self.pad[i], \n",
    "                                           n_basis_kernels = self.n_basis_kernels, \n",
    "                                           temperature=self.temperature, \n",
    "                                           pool_dim=self.pool_dim)\n",
    "                            ) \n",
    "\n",
    "            \n",
    "            cnn.add_module(\"batchNorm{0}\".format(i), \n",
    "                           nn.BatchNorm2d(out_dim[i], momentum = 0.99)\n",
    "                           )\n",
    "                \n",
    "            cnn.add_module(\"activ{0}\".format(i), \n",
    "                           nn.ReLU())\n",
    "            \n",
    "            if dropout is not None: \n",
    "                cnn.add_module(\"dropout{0}\".format(i),\n",
    "                               nn.Dropout(dropout))\n",
    "                 \n",
    "            cnn.add_module(\"pooling{0}\".format(i), \n",
    "                           nn.MaxPool2d(self.maxPooling[i]))\n",
    "            \n",
    "            if i == 0:\n",
    "                self.h_conv[0] = int((self.shape_data[1] - self.kernel_size[0] + 3 ))\n",
    "                self.w_conv[0] = int((self.shape_data[2] - self.kernel_size[0] + 3)) \n",
    "\n",
    "                self.h_pool[0] = int((self.h_conv[0] - self.maxPooling[0])/self.maxPooling[0] + 1)\n",
    "                self.w_pool[0] = int((self.w_conv[0] - self.maxPooling[0])/self.maxPooling[0] + 1)\n",
    "            \n",
    "            else:\n",
    "                self.h_conv[i] = int((self.h_pool[i-1] - self.kernel_size[i] + 3 ))\n",
    "                self.w_conv[i] = int((self.w_pool[i-1] - self.kernel_size[i] + 3 ))\n",
    "                \n",
    "                self.h_pool[i] = int((self.h_conv[i] - self.maxPooling[i])/self.maxPooling[i] + 1)\n",
    "                self.w_pool[i] = int((self.w_conv[i] - self.maxPooling[i])/self.maxPooling[i] + 1)\n",
    "        \n",
    "        \n",
    "        for i in range(self.num_layers):  \n",
    "            conv(i, dropout= self.dropout)       \n",
    "        self.cnn = cnn\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features= out_dim[self.num_layers-1]*self.h_pool[self.num_layers-1]*self.w_pool[self.num_layers-1], out_features= self.d_linear)\n",
    "        self.batch_norm = nn.BatchNorm1d(num_features=self.d_linear)\n",
    "        self.fc2 = nn.Linear(in_features=self.d_linear, out_features=34)\n",
    "        #self.drop = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):  # x size : [batch, channel, frames, freqs] 32, 3, 10,114   ```` 32,136 \n",
    "        batch = x.shape[0]\n",
    "        # print(x.shape)\n",
    "        \n",
    "        x = self.cnn(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # print(x.shape)\n",
    "        x = self.fc1(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        # x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x.reshape(batch, 17, 2)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Estimator(shape_data = (3,136,32)).to(\"cuda\")\n",
    "\n",
    "summary(model, (3, 136, 32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, denoiser, predictor):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        # Denoiser\n",
    "        self.denoiser = denoiser\n",
    "        # FD CNN\n",
    "        self.predictor = predictor\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            encoded = self.denoiser(x)\n",
    "        output = self.predictor(encoded)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "AE = Denoiser(shape_data = (3,136,32), n_kernels = [26,183], kernel_size = [3,3], maxpooling = [2,2])\n",
    "\n",
    "CNN_input_shape = (AE.encoder.n_kernels[-1], AE.encoder.h_pool2, AE.encoder.w_pool2)\n",
    "\n",
    "CNN = Estimator(shape_data=CNN_input_shape, \n",
    "                              dropout=0.1,\n",
    "                              n_basis_kernels=16,\n",
    "                              kernel_size=[2,2,2,2,2],\n",
    "                              n_kernels=[16,16,16,16,16],\n",
    "                              num_layers= 5,\n",
    "                              pad=[1,1,1,1,1,1],\n",
    "                              stride = [1,1,1,1,1],\n",
    "                              maxPooling= (3,3,2,2,2),\n",
    "                              temperature=30, \n",
    "                              pool_dim='time',\n",
    "                              d_linear = 256\n",
    "                              )\n",
    "\n",
    "model = CombinedModel(AE.encoder, CNN)\n",
    "model = model.to(device)\n",
    "summary(model, (3, 136, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Denoise_Trainer:\n",
    "    def __init__(self, model, train_loader, val_loader, test_loader, criterion, optimizer,\n",
    "                 scheduler, model_save_path=\"checkpoints\"):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.model_save_path = model_save_path\n",
    "        self.metric = dict()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.train_epoch_idx = 0\n",
    "        self.val_epoch_idx = 0\n",
    "\n",
    "    def train_epoch(self):\n",
    "        # print(f\"Training Denoiser. Epoch: {self.train_epoch_idx}\")\n",
    "        self.metric[self.train_epoch_idx] = dict()\n",
    "        self.model.train()\n",
    "        losses = []\n",
    "        \n",
    "        for iter, (data, label) in enumerate(self.train_loader):\n",
    "            data = data.to(self.device)\n",
    "            label = label.to(self.device)\n",
    "            predict = self.model(data)\n",
    "            loss = self.criterion(predict, label)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            # print(f\"Iter {iter + self.train_epoch_idx * len(self.train_loader)}: MSE - {losses[-1]}\")\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        self.metric[self.train_epoch_idx][\"denoiser_train_loss\"] = sum(losses) / len(losses)\n",
    "        wandb.log({\"denoiser_train_loss\": sum(losses) / len(losses) })\n",
    "        self.train_epoch_idx += 1\n",
    "\n",
    "    def val_epoch(self):\n",
    "        # print(f\"Validating Denoiser. Epoch: {self.val_epoch_idx}\")\n",
    "        self.metric[self.train_epoch_idx] = dict()\n",
    "        self.model.eval()\n",
    "        losses = []\n",
    "        for data, label in self.val_loader:\n",
    "            data = data.to(self.device)\n",
    "            label = label.to(self.device)\n",
    "            with torch.no_grad():\n",
    "                predict = self.model(data)\n",
    "            loss = self.criterion(predict, label)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        self.metric[self.val_epoch_idx][\"denoiser_val_loss\"] = sum(losses) / len(losses)\n",
    "        wandb.log({\"denoiser_val_loss\": sum(losses) / len(losses) })\n",
    "        # print(f\"Val loss: {sum(losses) / len(losses)}\")\n",
    "        if self.val_epoch_idx == 0 or \\\n",
    "                self.metric[self.val_epoch_idx][\"denoiser_val_loss\"] < self.metric[self.val_epoch_idx - 1][\"denoiser_val_loss\"]:\n",
    "            self.save_model()\n",
    "            # print(f\"Denoiser Model is saved at epoch {self.val_epoch_idx}\")\n",
    "        self.val_epoch_idx += 1\n",
    "\n",
    "    def test_epoch(self):\n",
    "        # print(f\"Testing Denoiser\")\n",
    "        # self.model.load_state_dict(torch.load(\"/home/nxhoang/Work/HPE-VinUni/src/model/checkpoints/model_best.pth\")['model_state_dict'])\n",
    "        self.model.eval()\n",
    "        losses = []\n",
    "        for data, label in tqdm(self.test_loader):\n",
    "            data = data.to(self.device)\n",
    "            label = label.to(self.device)\n",
    "            with torch.no_grad():\n",
    "                predict = self.model(data)\n",
    "            loss = self.criterion(predict, label)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        self.metric[\"test\"] = sum(losses) / len(losses)\n",
    "        wandb.log({\"Denoiser test result\": self.metric[\"test\"]})\n",
    "        # print(f\"Denoiser test result: {self.metric['test']}\")\n",
    "\n",
    "    def save_model(self):\n",
    "        state_dict = dict()\n",
    "        state_dict[\"model_state_dict\"] = self.model.state_dict()\n",
    "        state_dict[\"optimizer_state_dict\"] = self.optimizer.state_dict()\n",
    "        state_dict[\"train_loss_history\"] = torch.tensor([self.metric[i][\"denoiser_train_loss\"] for i in range(self.train_epoch_idx)])\n",
    "        state_dict[\"val_loss_history\"] = torch.tensor([self.metric[i][\"denoiser_val_loss\"] for i in range(self.val_epoch_idx)])\n",
    "\n",
    "        save_path = os.path.join(self.model_save_path, f\"model_best.pth\")\n",
    "        torch.save(state_dict, save_path)\n",
    "\n",
    "\n",
    "class Estimastor_Trainer:\n",
    "    def __init__(self, model, train_loader, val_loader, test_loader, criterion, optimizer,\n",
    "                 scheduler = None, model_save_path=\"checkpoints\"):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        # self.scheduler = scheduler\n",
    "        self.model_save_path = model_save_path\n",
    "        self.metric = dict()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.train_epoch_idx = 0\n",
    "        self.val_epoch_idx = 0\n",
    "        self.min_val_loss = 9999\n",
    "\n",
    "    def train_epoch(self):\n",
    "        # print(f\"Training Estimator.  Epoch {self.train_epoch_idx}\")\n",
    "        self.metric[self.train_epoch_idx] = dict()\n",
    "        self.model.train()\n",
    "        losses = []\n",
    "\n",
    "        for iter, (data, gt) in enumerate(self.train_loader):\n",
    "            # print(data.shape)\n",
    "            data = np.transpose(data, (0, 1, 3, 2))\n",
    "            # print('data_shape', data.shape)\n",
    "            data = data.to(self.device)\n",
    "            confidence = gt[:, :, 2:].to(self.device)\n",
    "            # print('shape confidence', confidence.shape)\n",
    "            label = gt[:, :, 0:2].to(self.device)\n",
    "            # print('shape label', label.shape)\n",
    "            predict = self.model(data)\n",
    "            # print('shape predict', predict.shape)\n",
    "\n",
    "            loss = self.criterion(torch.mul(predict, confidence), torch.mul(label, confidence)) / 32\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            # print(f\"Iter {iter + self.train_epoch_idx * len(self.train_loader)}: MSE - {losses[-1]}\")\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        # self.scheduler.step()\n",
    "\n",
    "        self.metric[self.train_epoch_idx][\"train_loss\"] = sum(losses) / len(losses)\n",
    "        wandb.log({\"Estimator Training Loss\": self.metric[self.train_epoch_idx][\"train_loss\"]})   \n",
    "        self.train_epoch_idx += 1\n",
    "\n",
    "    def val_epoch(self):\n",
    "        # print(f\"Validating Estimator. Epoch {self.val_epoch_idx}\")\n",
    "        self.metric[self.train_epoch_idx] = dict()\n",
    "        self.model.eval()\n",
    "\n",
    "        pck_50_iter = []\n",
    "        pck_40_iter = []\n",
    "        pck_30_iter = []\n",
    "        pck_20_iter = []\n",
    "        pck_10_iter = []\n",
    "        pck_5_iter = []\n",
    "\n",
    "        error_iter = []\n",
    "\n",
    "\n",
    "        losses = []\n",
    "        for data, gt in self.val_loader:\n",
    "            data = np.transpose(data, (0, 1, 3, 2)) # [batch size, channels, freq, time]\n",
    "            data = data.to(self.device)\n",
    "            label = gt[:, :, 0:2].to(self.device) #xy_keypoint\n",
    "\n",
    "            confidence = gt[:, :, 2:3].to(self.device)\n",
    "            with torch.no_grad():\n",
    "                predict = self.model(data)\n",
    "            loss = self.criterion(torch.mul(confidence, predict), torch.mul(confidence, label))\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            predict = predict.cpu()\n",
    "            label = label.cpu()\n",
    "\n",
    "            predict = torch.transpose(predict, 1, 2)\n",
    "            label = torch.transpose(label, 1, 2)\n",
    "\n",
    "            pck_50_iter.append(compute_pck_pckh(predict, label, 0.5))\n",
    "            pck_40_iter.append(compute_pck_pckh(predict, label, 0.4))\n",
    "            pck_30_iter.append(compute_pck_pckh(predict, label, 0.3))\n",
    "            pck_20_iter.append(compute_pck_pckh(predict, label, 0.2))\n",
    "            pck_10_iter.append(compute_pck_pckh(predict, label, 0.1))\n",
    "            pck_5_iter.append(compute_pck_pckh(predict, label, 0.05))\n",
    "\n",
    "            error_iter.append(calculate_error(predict,label))\n",
    "\n",
    "            \n",
    "        error = np.mean(error_iter,0)*1000   \n",
    "        self.metric[self.val_epoch_idx][\"val loss\"] = sum(losses) / len(losses)\n",
    "        self.metric[self.val_epoch_idx][\"pck_50\"] = sum(pck_50_iter) / len(pck_50_iter)\n",
    "        self.metric[self.val_epoch_idx][\"pck_40\"] = sum(pck_40_iter) / len(pck_40_iter)\n",
    "        self.metric[self.val_epoch_idx][\"pck_30\"] = sum(pck_30_iter) / len(pck_30_iter)\n",
    "        self.metric[self.val_epoch_idx][\"pck_20\"] = sum(pck_20_iter) / len(pck_20_iter)\n",
    "        self.metric[self.val_epoch_idx][\"pck_10\"] = sum(pck_10_iter) / len(pck_10_iter)\n",
    "        self.metric[self.val_epoch_idx][\"pck_5\"] = sum(pck_5_iter) / len(pck_5_iter)\n",
    "        self.metric[self.val_epoch_idx][\"mpjpe\"] = error[0]\n",
    "        self.metric[self.val_epoch_idx][\"pampjpe\"] = error[1]\n",
    "\n",
    "        loss_avg = sum(losses) / len(losses)\n",
    "        # print(f\"Val loss: {loss_avg}\")\n",
    "        # print(\"pck_50: \", sum(pck_50_iter) / len(pck_50_iter))\n",
    "        # print(\"pck_40: \", sum(pck_40_iter) / len(pck_40_iter))\n",
    "        # print(\"pck_30: \", sum(pck_30_iter) / len(pck_30_iter))\n",
    "        # print(\"pck_20: \", sum(pck_20_iter) / len(pck_20_iter))\n",
    "        # print(\"pck_10: \", sum(pck_10_iter) / len(pck_10_iter))\n",
    "        # print(\"pck_5: \", sum(pck_5_iter) / len(pck_5_iter))\n",
    "\n",
    "        wandb.log({'estimator_val_loss': loss_avg})\n",
    "        wandb.log({'pck_50 Val': sum(pck_50_iter) / len(pck_50_iter)})\n",
    "        wandb.log({'pck_40 Val': sum(pck_40_iter) / len(pck_40_iter)})\n",
    "        wandb.log({'pck_30 Val': sum(pck_30_iter) / len(pck_30_iter)})\n",
    "        wandb.log({'pck_20 Val': sum(pck_20_iter) / len(pck_20_iter)})\n",
    "        wandb.log({'pck_10 Val': sum(pck_10_iter) / len(pck_10_iter)})\n",
    "        wandb.log({'pck_5 Val': sum(pck_5_iter) / len(pck_5_iter)})\n",
    "        wandb.log({'mpjpe Val': error[0]})\n",
    "        wandb.log({'pampjpe Val': error[1]})\n",
    "     \n",
    "\n",
    "        # logs = \"Val loss: \" + str(sum(losses) / len(losses)) + \", \"\n",
    "        # logs += \"pck_50: \" + str(sum(pck_50_iter) / len(pck_50_iter)) + \", \"\n",
    "        # logs += \"pck_40: \" + str(sum(pck_40_iter) / len(pck_40_iter)) + \", \"\n",
    "        # logs += \"pck_30: \" + str(sum(pck_30_iter) / len(pck_30_iter)) + \", \"\n",
    "        # logs += \"pck_20: \" + str(sum(pck_20_iter) / len(pck_20_iter)) + \", \"\n",
    "        # logs += \"pck_10: \" + str(sum(pck_10_iter) / len(pck_10_iter)) + \", \"\n",
    "        # logs += \"pck_5: \" + str(sum(pck_5_iter) / len(pck_5_iter)) + \"\\n\"\n",
    "        \n",
    "        # with open(\"/home/nxhoang/Work/HPE/src/model/logs/combined_model.txt\", \"a\") as f:\n",
    "        \n",
    "        #     f.write(logs)\n",
    "\n",
    "        if self.val_epoch_idx == 0 or \\\n",
    "                self.metric[self.val_epoch_idx][\"val loss\"] < self.min_val_loss:\n",
    "            self.min_val_loss = self.metric[self.val_epoch_idx][\"val loss\"]\n",
    "            self.save_model()\n",
    "            # print(f\"Estimator Model is saved at epoch {self.val_epoch_idx}\")\n",
    "        self.val_epoch_idx += 1\n",
    "\n",
    "    def test_epoch(self):\n",
    "        # print(f\"Estmator Testing\")\n",
    "        self.model.load_state_dict(torch.load(\"/home/nxhoang/Work/HPE-VinUni/src/model/checkpoints/model_best.pth\")['model_state_dict'])\n",
    "        self.model.eval()\n",
    "        pck_50_iter = []\n",
    "        pck_40_iter = []\n",
    "        pck_30_iter = []\n",
    "        pck_20_iter = []\n",
    "        pck_10_iter = []\n",
    "        pck_5_iter = []\n",
    "        error_iter = []\n",
    "        losses = []\n",
    "        for data, gt in tqdm(self.test_loader):\n",
    "            data = np.transpose(data, (0, 1, 3, 2))  # [batch size, channels, freq, time]\n",
    "            data = data.to(self.device)\n",
    "            label = gt[:, :, 0:2].to(self.device)\n",
    "            confidence = gt[:, :, 2:].to(self.device)\n",
    "            with torch.no_grad():\n",
    "                predict = self.model(data)\n",
    "            loss = self.criterion(torch.mul(predict, confidence), torch.mul(label, confidence))\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            predict = predict.cpu()\n",
    "            label = label.cpu()\n",
    "            predict = torch.transpose(predict, 1, 2)\n",
    "            label = torch.transpose(label, 1, 2)\n",
    "\n",
    "            pck_50_iter.append(compute_pck_pckh(predict, label, 0.5))\n",
    "            pck_40_iter.append(compute_pck_pckh(predict, label, 0.4))\n",
    "            pck_30_iter.append(compute_pck_pckh(predict, label, 0.3))\n",
    "            pck_20_iter.append(compute_pck_pckh(predict, label, 0.2))\n",
    "            pck_10_iter.append(compute_pck_pckh(predict, label, 0.1))\n",
    "            pck_5_iter.append(compute_pck_pckh(predict, label, 0.05))\n",
    "\n",
    "            error_iter.append(calculate_error(predict,label))\n",
    "\n",
    "        error = np.mean(error_iter,0)*1000\n",
    "        self.metric[\"test\"] = dict()\n",
    "        self.metric[\"test\"][\"loss\"] = sum(losses) / len(losses)\n",
    "        self.metric[\"test\"][\"pck_50\"] = sum(pck_50_iter) / len(pck_50_iter)\n",
    "        self.metric[\"test\"][\"pck_40\"] = sum(pck_40_iter) / len(pck_40_iter)\n",
    "        self.metric[\"test\"][\"pck_30\"] = sum(pck_30_iter) / len(pck_30_iter)\n",
    "        self.metric[\"test\"][\"pck_20\"] = sum(pck_20_iter) / len(pck_20_iter)\n",
    "        self.metric[\"test\"][\"pck_10\"] = sum(pck_10_iter) / len(pck_10_iter)\n",
    "        self.metric[\"test\"][\"pck_5\"] = sum(pck_5_iter) / len(pck_5_iter)\n",
    "        self.metric[\"test\"][\"mpjpe_mean\"] = error[0]\n",
    "        self.metric[\"test\"][\"pampjpe_mean\"] = error[1]\n",
    "        \n",
    "\n",
    "        wandb.log({'Estimator Loss Test': sum(losses) / len(losses)})\n",
    "        wandb.log({'pck_50': sum(pck_50_iter) / len(pck_50_iter)})\n",
    "        wandb.log({'pck_40': sum(pck_40_iter) / len(pck_40_iter)})\n",
    "        wandb.log({'pck_30': sum(pck_30_iter) / len(pck_30_iter)})\n",
    "        wandb.log({'pck_20': sum(pck_20_iter) / len(pck_20_iter)})\n",
    "        wandb.log({'pck_10': sum(pck_10_iter) / len(pck_10_iter)})\n",
    "        wandb.log({'pck_5': sum(pck_5_iter) / len(pck_5_iter)})\n",
    "        wandb.log({'mpjpe': error[0]})\n",
    "        wandb.log({'pampjpe': error[1]})\n",
    "\n",
    "\n",
    "    def save_model(self):\n",
    "        state_dict = dict()\n",
    "        state_dict[\"model_state_dict\"] = self.model.state_dict()\n",
    "        state_dict[\"optimizer_state_dict\"] = self.optimizer.state_dict()\n",
    "        state_dict[\"train_loss_history\"] = torch.tensor([self.metric[i][\"train_loss\"] for i in range(self.train_epoch_idx)])\n",
    "        state_dict[\"val_loss_history\"] = torch.tensor([self.metric[i][\"val loss\"] for i in range(self.val_epoch_idx)])\n",
    "        state_dict[\"pck_50\"] = self.metric[self.val_epoch_idx][\"pck_50\"]\n",
    "        state_dict[\"pck_40\"] = self.metric[self.val_epoch_idx][\"pck_40\"]\n",
    "        state_dict[\"pck_30\"] = self.metric[self.val_epoch_idx][\"pck_30\"]\n",
    "        state_dict[\"pck_20\"] = self.metric[self.val_epoch_idx][\"pck_20\"]\n",
    "        state_dict[\"pck_10\"] = self.metric[self.val_epoch_idx][\"pck_10\"]\n",
    "        state_dict[\"pck_5\"] = self.metric[self.val_epoch_idx][\"pck_5\"]\n",
    "        state_dict[\"mpjpe\"] = self.metric[self.val_epoch_idx][\"mpjpe\"]\n",
    "        state_dict[\"pampjpe\"] = self.metric[self.val_epoch_idx][\"pampjpe\"]\n",
    "        save_path = os.path.join(self.model_save_path, f\"model_best.pth\")\n",
    "        torch.save(state_dict, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/nxhoang/Work/HPE-VinUni/src/model/configs/Final_BO.yaml') as f:\n",
    "  sweep_config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_config = {'modality': 'wifi-csi',\n",
    "                        'protocol': 'protocol2',\n",
    "                        'data_unit': 'frame',\n",
    "                        'random_split': {'ratio': 0.8,\n",
    "                                         'random_seed': 42,\n",
    "                                         'train_dataset': {'split': 'training',\n",
    "                                                            'scenes': 'None',\n",
    "                                                            'subjects': 'None',\n",
    "                                                          'actions': 'all'},\n",
    "                                          'val_dataset': {'split': 'validation',\n",
    "                                                          'scenes': 'None',\n",
    "                                                          'subjects': 'None',\n",
    "                                                          'actions': 'all'}},\n",
    "                        'cross_scene_split': {'train_dataset': {'split': 'training',\n",
    "                                              'scenes': ['E01', 'E02', 'E03'],\n",
    "                                              'subjects': 'None',\n",
    "                                              'actions': 'all'},\n",
    "                                              'val_dataset': {'split': 'validation',\n",
    "                                                              'scenes': ['E04'],\n",
    "                                                              'subjects': 'None',\n",
    "                                                              'actions': 'all'}},\n",
    "                        'cross_subject_split': {'train_dataset': {'split': 'training',\n",
    "                                                                  'scenes': 'None',\n",
    "                                                                  'subjects': ['S01','S02','S03','S04','S06','S07','S08','S09','S11','S12','S13','S14','S16','S17','S18','S19','S21','S22','S23','S24','S26','S27','S28','S29','S31','S32','S33','S34','S36','S37','S38','S39'],\n",
    "                                                                  'actions': 'all'},\n",
    "                                                'val_dataset': {'split': 'validation',\n",
    "                                                                'scenes': 'None',\n",
    "                                                                'subjects': ['S05', 'S10', 'S15', 'S20', 'S25', 'S30', 'S35', 'S40'],\n",
    "                                                                'actions': 'all'}},\n",
    "                        'manual_split': {'train_dataset': {'split': 'training',\n",
    "                                                           'scenes': 'None',\n",
    "                                                           'subjects': ['S01','S02','S03','S04','S05','S06','S07','S08','S09','S10','S11','S12','S13','S14','S15','S16','S17','S18','S19','S20','S21','S22','S23','S24','S25','S26','S27','S28','S29','S30','S31','S32','S33','S34','S35','S36','S37','S38','S39','S40'],\n",
    "                                                           'actions': ['A01','A02','A03','A04','A05','A06','A07','A08','A09','A10','A11','A12','A13','A14','A15','A16','A17','A18','A19','A20','A21']},\n",
    "                                          'val_dataset': {'split': 'validation',\n",
    "                                                          'scenes': 'None',\n",
    "                                                          'subjects': ['S01','S02','S03','S04','S05','S06','S07','S08','S09','S10','S11','S12','S13','S14','S15','S16','S17','S18','S19','S20','S21','S22','S23','S24','S25','S26','S27','S28','S29','S30','S31','S32','S33','S34','S35','S36','S37','S38','S39','S40'],\n",
    "                                                          'actions': ['A22', 'A23', 'A24', 'A25', 'A26', 'A27']}},\n",
    "                        'split_to_use': 'random_split',\n",
    "                        'init_rand_seed': 0,\n",
    "                        'data_root': '/home/nxhoang/Work/HPE-VinUni/Data',\n",
    "                        'AE_checkpoint': '/home/nxhoang/Work/HPE-VinUni/src/model/checkpoints/AE_model_best.pth',\n",
    "                        'combined_checkpoint': '/home/nxhoang/Work/HPE-VinUni/src/model/checkpoints/combined_model_best.pth'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ae_train_dataset = torch.load('/home/nxhoang/Work/HPE-VinUni/Processed_Data/Protocol_1/ae_train_noise10_norm.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ae_test_dataset = torch.load('/home/nxhoang/Work/HPE-VinUni/Processed_Data/Protocol_1/ae_test_noise10_norm.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# est_train_dataset = torch.load('/home/nxhoang/Work/HPE-VinUni/Processed_Data/Protocol_1/est_train_noise10_norm.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# est_test_dataset = torch.load('/home/nxhoang/Work/HPE-VinUni/Processed_Data/Protocol_1/est_test_noise10_norm.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training \n",
    "def training():\n",
    "     with wandb.init(config=sweep_config):\n",
    "        config = wandb.config\n",
    "        \n",
    "        # start = time.perf_counter()\n",
    "        \n",
    "    ## Create noise dataset\n",
    "       \n",
    "        data_shape = (3,136,32)\n",
    "        # print(\"data_shape\",)\n",
    "\n",
    "        ae_train_dataset, ae_test_dataset = ae_make_dataset(other_config[\"data_root\"], other_config)\n",
    "        rng_generator = torch.manual_seed(other_config['init_rand_seed'])\n",
    "        train_loader = ae_make_dataloader(ae_train_dataset, is_training=True, generator=rng_generator, batch_size = config['ae_batch_size'])\n",
    "        val_data, test_data = train_test_split(ae_test_dataset, test_size=0.5, random_state=41)\n",
    "        val_loader = ae_make_dataloader(val_data, is_training=False, generator=rng_generator, batch_size = config['ae_batch_size'])\n",
    "        test_loader = ae_make_dataloader(test_data, is_training=False, generator=rng_generator, batch_size = config['ae_batch_size'])\n",
    "        \n",
    "        \n",
    "        # Define device\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "        #Initialize autoencoder denoiser\n",
    "        denoiser = Denoiser(shape_data=data_shape, \n",
    "                            n_kernels=(config['ae_n_kernels_1'], config['ae_n_kernels_2']), \n",
    "                            kernel_size= [config['ae_kernel_size_1'],config['ae_kernel_size_2']], \n",
    "                            maxpooling=([config['ae_maxpooling_1'], config['ae_maxpooling_2']])\n",
    "                            ) \n",
    "        denoiser.to(device)\n",
    "\n",
    "\n",
    "        # Train autoencoder denoiser \n",
    "        criterion_ae = nn.MSELoss().to(device)\n",
    "        optimizer_ae = torch.optim.RMSprop(denoiser.parameters(), lr=config['ae_lr'], momentum=config['ae_momentum'])\n",
    "        # optimizer_ae = torch.optim.Adam(denoiser.parameters(), lr=config['ae_lr'])\n",
    "        \n",
    "        n_epochs_ae = config['ae_n_epochs']\n",
    "\n",
    "        \n",
    "        schedule_ae = LambdaLR(optimizer_ae, lr_lambda=lambda epoch: 1 if epoch < 45 else torch.exp(-0.1))\n",
    "\n",
    "        trainer_ae = Denoise_Trainer(denoiser, train_loader, val_loader, test_loader, criterion=criterion_ae,\n",
    "                                     optimizer=optimizer_ae, scheduler=schedule_ae)\n",
    "        \n",
    "        print(\"START TRAINING DENOISER AT: \", time.perf_counter_ns())\n",
    "        for epoch in range(n_epochs_ae):\n",
    "            trainer_ae.train_epoch()\n",
    "            trainer_ae.val_epoch()\n",
    "        print(\"END TRAINING DENOISER AT\", time.perf_counter_ns())\n",
    "        trainer_ae.test_epoch()\n",
    "        \n",
    "        config[\"denoiser_loss\"] = trainer_ae.metric[\"test\"] #loss of AE after testing \n",
    "\n",
    "\n",
    "        # Extract Encoder part\n",
    "        en_denoiser = denoiser.encoder\n",
    "        en_denoiser.eval()\n",
    "        for param in en_denoiser.parameters():\n",
    "            param.requires_grad = False  # Freeze parameters\n",
    "\n",
    "        #================================================ Initialize estimator ======================================#\n",
    "        cnn_input_shape = (en_denoiser.n_kernels[-1], en_denoiser.h_pool2, en_denoiser.w_pool2)\n",
    "        \n",
    "        estimator = Estimator(shape_data=cnn_input_shape, \n",
    "                              dropout=config['est_dropout'],\n",
    "                              n_basis_kernels=config['est_n_basis_kernels'],\n",
    "                              kernel_size=(config['est_kernel_size_1'], config['est_kernel_size_2'], config['est_kernel_size_3']),\n",
    "                              n_kernels=(config['est_n_kernels_1'], config['est_n_kernels_2'], config['est_n_kernels_3']),\n",
    "                              num_layers=config['est_num_layers'],\n",
    "                              pad=[1,1,1,1,1],\n",
    "                              stride = [1,1,1,1,1],\n",
    "                              maxPooling= (config['est_maxpooling_1'],  config['est_maxpooling_2'], config['est_maxpooling_3']),\n",
    "                              temperature=config['est_temperature'], \n",
    "                              pool_dim='time',\n",
    "                              d_linear = config['est_d_hidden']\n",
    "                              )\n",
    "\n",
    "\n",
    "        # Initialize a combined model\n",
    "        combined_model = CombinedModel(en_denoiser, estimator).to(device)\n",
    "\n",
    "        est_train_dataset, est_test_dataset = est_make_dataset(other_config[\"data_root\"], other_config)\n",
    "        rng_generator1 = torch.manual_seed(other_config['init_rand_seed'])\n",
    "        train_loader1 = est_make_dataloader(est_train_dataset, is_training=True, generator=rng_generator1,\n",
    "                                                 batch_size = config['est_batch_size'])\n",
    "        val_data1, test_data1 = train_test_split(est_test_dataset, test_size=0.5, random_state=41)\n",
    "        val_loader1 = est_make_dataloader(val_data1, is_training=False, generator=rng_generator1,\n",
    "                                               batch_size = config['est_batch_size'])\n",
    "        test_loader1 = est_make_dataloader(test_data1, is_training=False, generator=rng_generator1,\n",
    "                                                batch_size = config['est_batch_size'])\n",
    "\n",
    "        # Training combined_model with Encoder parameters being frozen\n",
    "        criterion_cb = nn.MSELoss().to(device)\n",
    "        # optimizer_cb = torch.optim.SGD(combined_model.parameters(), lr=config['est_lr'], momentum=config['est_momentum'])\n",
    "        optimizer_cb = torch.optim.Adam(combined_model.parameters(), lr=config['est_lr'])\n",
    "\n",
    "        n_epochs_cb = config[\"est_n_epochs\"]\n",
    "      \n",
    "        # n_epochs_decay = 60\n",
    "        # epoch_count = 1\n",
    "\n",
    "        # def lambda_rule(epoch):\n",
    "        #     lr_l = 1.0 - max(0, epoch + epoch_count - n_epochs_cb) / float(n_epochs_decay + 1)\n",
    "        #     return lr_l\n",
    "\n",
    "        # scheduler_cb = torch.optim.lr_scheduler.LambdaLR(optimizer_cb, lr_lambda=lambda epoch: 1.0 - max(0,\n",
    "        #                                                                                                  epoch + epoch_count - n_epochs_cb) / float(\n",
    "        #     n_epochs_decay + 1))\n",
    "\n",
    "\n",
    "        trainer_cb = Estimastor_Trainer(combined_model, train_loader1, val_loader1, test_loader1, criterion=criterion_cb,\n",
    "                                        optimizer=optimizer_cb, scheduler=None)\n",
    "        \n",
    "        print(\"START TRAINING ESTIMATOR AT: \", time.perf_counter_ns())\n",
    "        for epoch in range(n_epochs_cb):\n",
    "            trainer_cb.train_epoch()\n",
    "            trainer_cb.val_epoch()\n",
    "        print(\"END TRAINING ESTIMATOR AT: \", time.perf_counter_ns())    \n",
    "        trainer_cb.test_epoch()\n",
    "\n",
    "        config['estimator_loss'] = trainer_cb.metric[\"test\"][\"loss\"] \n",
    "        if trainer_cb.metric[\"test\"][\"loss\"] < 0.1:\n",
    "            wandb.alert(\n",
    "                title='Xuan Hoang just found the best loss_val',\n",
    "                text=f'Val Loss{trainer_cb.metric[\"test\"][\"loss\"]} is below 0.1',\n",
    "            )\n",
    "            print('Alert triggered') \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep = sweep_config, project =\"Denoiser + Estimator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298747be3f3c4f3d89e12bc7731fe77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!date\n",
    "wandb.agent(sweep_id, function=training, count=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
