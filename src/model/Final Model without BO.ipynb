{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# import argparse\n",
    "import sys\n",
    "import torch\n",
    "import yaml\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "\n",
    "from ae_dataset import make_dataset as ae_make_dataset\n",
    "from ae_dataset import make_dataloader as ae_make_dataloader\n",
    "\n",
    "from est_dataset import make_dataset as est_make_dataset\n",
    "from est_dataset import make_dataloader as est_make_dataloader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from metrics import compute_pck_pckh, calculate_error\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some codes are adopted from cite dynamic cnn \n",
    "\n",
    "class Dynamic_conv2d(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, bias=False, n_basis_kernels=4,\n",
    "                 temperature=31, pool_dim='freq'):\n",
    "        super(Dynamic_conv2d, self).__init__()\n",
    "\n",
    "        self.in_planes = in_planes\n",
    "        self.out_planes = out_planes\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.pool_dim = pool_dim\n",
    "\n",
    "        self.n_basis_kernels = n_basis_kernels\n",
    "        self.attention = attention2d(in_planes, self.kernel_size, self.stride, self.padding, n_basis_kernels,\n",
    "                                     temperature, pool_dim)\n",
    "\n",
    "        self.weight = nn.Parameter(torch.randn(n_basis_kernels, out_planes, in_planes, self.kernel_size, self.kernel_size),\n",
    "                                   requires_grad=True)\n",
    "\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(n_basis_kernels, out_planes))\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        for i in range(self.n_basis_kernels):\n",
    "            nn.init.kaiming_normal_(self.weight[i])\n",
    "\n",
    "    def forward(self, x): #x size : [bs, in_chan, frames, freqs]   -> new: [bs, in_chan, freqs, frames]\n",
    "        if self.pool_dim in ['freq', 'chan']:\n",
    "            # softmax_attention = self.attention(x).unsqueeze(2).unsqueeze(4)    # size : [bs, n_ker, 1, frames, 1]\n",
    "            softmax_attention = self.attention(x).unsqueeze(2).unsqueeze(3)    # size : [bs, n_ker, 1,1,frames]\n",
    "        elif self.pool_dim == 'time':\n",
    "            softmax_attention = self.attention(x).unsqueeze(2).unsqueeze(4)    # size : [bs, n_ker, 1, freqs, 1]\n",
    "        elif self.pool_dim == 'both':\n",
    "            softmax_attention = self.attention(x).unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)    # size : [bs, n_ker, 1, 1, 1]\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        aggregate_weight = self.weight.view(-1, self.in_planes, self.kernel_size, self.kernel_size) # size : [n_ker * out_chan, in_chan]\n",
    "\n",
    "        if self.bias is not None:\n",
    "            aggregate_bias = self.bias.view(-1)\n",
    "            output = F.conv2d(x, weight=aggregate_weight, bias=aggregate_bias, stride=self.stride, padding=self.padding)\n",
    "        else:\n",
    "            output = F.conv2d(x, weight=aggregate_weight, bias=None, stride=self.stride, padding=self.padding)\n",
    "            # output size : [bs, n_ker * out_chan, frames, freqs]\n",
    "\n",
    "        output = output.view(batch_size, self.n_basis_kernels, self.out_planes, output.size(-2), output.size(-1))\n",
    "        # output size : [bs, n_ker, out_chan, frames, freqs]\n",
    "\n",
    "        if self.pool_dim in ['freq', 'chan']:\n",
    "            assert softmax_attention.shape[-1] == output.shape[-1]\n",
    "        elif self.pool_dim == 'time':\n",
    "            assert softmax_attention.shape[-2] == output.shape[-2]\n",
    "\n",
    "        output = torch.sum(output * softmax_attention, dim=1)  # output size : [bs, out_chan, frames, freqs]\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class attention2d(nn.Module):\n",
    "    def __init__(self, in_planes, kernel_size, stride, padding, n_basis_kernels, temperature, pool_dim):\n",
    "        super(attention2d, self).__init__()\n",
    "        self.pool_dim = pool_dim\n",
    "        self.temperature = temperature\n",
    "\n",
    "        hidden_planes = int(in_planes / 4)\n",
    "\n",
    "        if hidden_planes < 4:\n",
    "            hidden_planes = 4\n",
    "\n",
    "        if not pool_dim == 'both':\n",
    "            self.conv1d1 = nn.Conv1d(in_planes, hidden_planes, kernel_size, stride=stride, padding=padding, bias=False)\n",
    "            self.bn = nn.BatchNorm1d(hidden_planes)\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "            self.conv1d2 = nn.Conv1d(hidden_planes, n_basis_kernels, 1, bias=True)\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv1d):\n",
    "                    nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                    if m.bias is not None:\n",
    "                        nn.init.constant_(m.bias, 0)\n",
    "                if isinstance(m, nn.BatchNorm1d):\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "        else:\n",
    "            self.fc1 = nn.Linear(in_planes, hidden_planes)\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "            self.fc2 = nn.Linear(hidden_planes, n_basis_kernels)\n",
    "\n",
    "\n",
    "    def forward(self, x): #CSI size : [bs, chan, freqs, frames] \n",
    "        if self.pool_dim == 'freq':\n",
    "            x = torch.mean(x, dim=2)  #x size : [bs, chan, frames] \n",
    "        elif self.pool_dim == 'time':\n",
    "            x = torch.mean(x, dim=3)  #x size : [bs, chan, freqs]\n",
    "        elif self.pool_dim == 'both':\n",
    "            # x = torch.mean(torch.mean(x, dim=2), dim=1)  #x size : [bs, chan]\n",
    "            x = F.adaptive_avg_pool2d(x, (1, 1)).squeeze(-1).squeeze(-1)\n",
    "        elif self.pool_dim == 'chan':\n",
    "            x = torch.mean(x, dim=1)  #x size : [bs, freqs, frames]\n",
    "\n",
    "        if not self.pool_dim == 'both':\n",
    "            x = self.conv1d1(x)               #x size : [bs, hid_chan, frames]\n",
    "            x = self.bn(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.conv1d2(x)               #x size : [bs, n_ker, frames]\n",
    "        else:\n",
    "            x = self.fc1(x)               #x size : [bs, hid_chan]\n",
    "            x = self.relu(x)\n",
    "            x = self.fc2(x)               #x size : [bs, n_ker]\n",
    "\n",
    "        return F.softmax(x / self.temperature, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 26, 136, 32]             728\n",
      "       BatchNorm2d-2          [-1, 26, 136, 32]              52\n",
      "              ReLU-3          [-1, 26, 136, 32]               0\n",
      "         MaxPool2d-4           [-1, 26, 68, 16]               0\n",
      "            Conv2d-5          [-1, 183, 68, 16]          43,005\n",
      "       BatchNorm2d-6          [-1, 183, 68, 16]             366\n",
      "              ReLU-7          [-1, 183, 68, 16]               0\n",
      "         MaxPool2d-8           [-1, 183, 34, 8]               0\n",
      "           Encoder-9           [-1, 183, 34, 8]               0\n",
      "           Conv2d-10           [-1, 183, 34, 8]         301,584\n",
      "             ReLU-11           [-1, 183, 34, 8]               0\n",
      "      BatchNorm2d-12           [-1, 183, 34, 8]             366\n",
      "         Upsample-13          [-1, 183, 68, 16]               0\n",
      "           Conv2d-14           [-1, 26, 68, 16]          42,848\n",
      "             ReLU-15           [-1, 26, 68, 16]               0\n",
      "      BatchNorm2d-16           [-1, 26, 68, 16]              52\n",
      "         Upsample-17          [-1, 26, 136, 32]               0\n",
      "           Conv2d-18           [-1, 3, 136, 32]             705\n",
      "             ReLU-19           [-1, 3, 136, 32]               0\n",
      "          Decoder-20           [-1, 3, 136, 32]               0\n",
      "================================================================\n",
      "Total params: 389,706\n",
      "Trainable params: 389,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 12.59\n",
      "Params size (MB): 1.49\n",
      "Estimated Total Size (MB): 14.13\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# DENOISER \n",
    "\n",
    "# Doi Batch Norm len truoc \n",
    "\n",
    "\n",
    "#d_hidden, dropout_ae\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, shape_data, n_kernels, kernel_size, maxpooling):\n",
    "        super().__init__()\n",
    "        self.shape_data = shape_data\n",
    "        self.n_kernels = n_kernels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.maxpooling = maxpooling \n",
    "\n",
    "      # input -> conv2d -> batchnorm -> maxpool2d ->conv2d -> batchnorm -> maxpool     \n",
    "       # layer1\n",
    "        self.conv1 = nn.Conv2d(\n",
    "                                in_channels=self.shape_data[0],\n",
    "                                out_channels=self.n_kernels[0],\n",
    "                                kernel_size=self.kernel_size[0],\n",
    "                                padding=1\n",
    "                               )\n",
    "        self.atv1 = nn.ReLU()\n",
    "        self.batchNorm1 = nn.BatchNorm2d(num_features=self.n_kernels[0])\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=self.maxpooling[0])     \n",
    "\n",
    "        # layer 2 \n",
    "        self.conv2 = nn.Conv2d(\n",
    "                                in_channels=self.n_kernels[0],\n",
    "                                out_channels=self.n_kernels[1],\n",
    "                                kernel_size=self.kernel_size[1],\n",
    "                                padding=1\n",
    "                                )\n",
    "        self.atv2 = nn.ReLU()\n",
    "        self.batchNorm2 = nn.BatchNorm2d(num_features=self.n_kernels[1])\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=self.maxpooling[1]) \n",
    "       \n",
    "        # height and weight of the output shape of conv1 \n",
    "        self.h_conv1 = int((self.shape_data[1] - self.kernel_size[0] + 3 )) # padding = 1\n",
    "        self.w_conv1 = int((self.shape_data[2] - self.kernel_size[0] + 3 ))      \n",
    "        \n",
    "        # output of max-pooling 1\n",
    "        self.h_pool1 = int((self.h_conv1 - self.maxpooling[0])/self.maxpooling[0] + 1)\n",
    "        # stride of max-pooling = maxpooling \n",
    "        self.w_pool1 = int((self.w_conv1 - self.maxpooling[0])/self.maxpooling[0] + 1) \n",
    "\n",
    "        # height and weight of the output shape of conv2 \n",
    "        self.h_conv2 = int(self.h_pool1 - self.kernel_size[1] + 3 ) # padding = 1\n",
    "        self.w_conv2 = int(self.w_pool1 - self.kernel_size[1] + 3 )      \n",
    "        \n",
    "        #output of max-pooling 2\n",
    "        self.h_pool2 = int((self.h_conv2 - self.maxpooling[1])/self.maxpooling[1] + 1)\n",
    "        self.w_pool2 = int((self.w_conv2 - self.maxpooling[1])/self.maxpooling[1] + 1) \n",
    "        \n",
    "        # # layer3\n",
    "        # self.conv3 = nn.Conv2d(in_channels=64, out_channels=3, kernel_size=3, padding=1)\n",
    "        # self.relu3 = nn.ReLU()\n",
    "        # self.pool3 = nn.MaxPool2d(kernel_size=2, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.pool1(self.batchNorm1(self.relu1(self.conv1(x))))\n",
    "        x = self.pool1(self.atv1(self.batchNorm1(self.conv1(x))))\n",
    "        x = self.pool2(self.atv2(self.batchNorm2(self.conv2(x))))\n",
    "\n",
    "       \n",
    "        # x = self.pool3(self.relu3(self.conv3(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, shape_data, n_kernels, kernel_size, maxpooling):\n",
    "        super().__init__()\n",
    "        self.shape_data = shape_data\n",
    "        self.n_kernels = n_kernels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.maxpooling = maxpooling \n",
    "\n",
    "        self.h_conv1 = int((self.shape_data[1] - self.kernel_size[0] + 3 ))\n",
    "        self.w_conv1 = int((self.shape_data[2] - self.kernel_size[0] + 3 ))   \n",
    "        self.h_pool1 = int((self.h_conv1 - self.maxpooling[0])/self.maxpooling[0] + 1)\n",
    "        self.w_pool1 = int((self.w_conv1 - self.maxpooling[0])/self.maxpooling[0] + 1) \n",
    "        \n",
    "        self.h_conv2 = int(self.h_pool1 - self.kernel_size[1] + 3 )\n",
    "        self.w_conv2 = int(self.w_pool1 - self.kernel_size[1] + 3)    \n",
    "        \n",
    "        self.h_pool2 = int((self.h_conv2 - self.maxpooling[1])/self.maxpooling[1] + 1)\n",
    "        self.w_pool2 = int((self.w_conv2 - self.maxpooling[1])/self.maxpooling[1] + 1) \n",
    "        \n",
    "        # Layer 3 ~ hidden layer\n",
    "        self.conv3 = nn.Conv2d(in_channels=self.n_kernels[1],\n",
    "                               out_channels=self.n_kernels[1],\n",
    "                               kernel_size=self.kernel_size[1],\n",
    "                               padding=1\n",
    "                               )\n",
    "        self.atv3 = nn.ReLU()\n",
    "        self.batchNorm3 = nn.BatchNorm2d(num_features=self.n_kernels[1])\n",
    "        # Upsampling:  desired_output_size = (32, 32)  # Upsample to 32x32\n",
    "        # upsample_layer = nn.Upsample(size=desired_output_size, mode='bilinear', align_corners=False)\n",
    "        self.up_pool3 = nn.Upsample(size =(self.h_conv2, self.w_conv2))\n",
    "\n",
    "        # Layer 4\n",
    "        self.conv4 = nn.Conv2d(in_channels=self.n_kernels[1],\n",
    "                               out_channels=self.n_kernels[0],\n",
    "                               kernel_size=self.kernel_size[0],\n",
    "                               padding=1 \n",
    "                                )\n",
    "        self.atv4 = nn.ReLU()\n",
    "        self.batchNorm4 = nn.BatchNorm2d(num_features=self.n_kernels[0])\n",
    "\n",
    "        self.up_pool4 = nn.Upsample(size = (self.h_conv1, self.w_conv1) )\n",
    "\n",
    "        # Layer 5  = output \n",
    "        self.conv5 = nn.Conv2d(in_channels=self.n_kernels[0],\n",
    "                               out_channels=self.shape_data[0],\n",
    "                               kernel_size=self.kernel_size[0],\n",
    "                               padding=1 \n",
    "                                )\n",
    "        self.atv5 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.up_pool3(self.batchNorm3(self.atv3(self.conv3(x))))\n",
    "        x = self.up_pool4(self.batchNorm4(self.atv4(self.conv4(x))))\n",
    "        x = self.atv5(self.conv5(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Denoiser(nn.Module):\n",
    "    def __init__(self, shape_data, n_kernels, kernel_size, maxpooling):\n",
    "        super().__init__()\n",
    "        self.shape_data = shape_data\n",
    "        self.n_kernels = n_kernels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.maxpooling = maxpooling\n",
    "        self.encoder = Encoder(self.shape_data,  self.n_kernels, self.kernel_size, self.maxpooling)\n",
    "        self.decoder = Decoder(self.shape_data,  self.n_kernels, self.kernel_size, self.maxpooling)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     test_model = AutoEncoder().to(\"cuda\")\n",
    "\n",
    "#     # ummary(test_model, input_size=(3, 32,136), batch_size=16, device=\"cuda\")\n",
    "#     pass\n",
    "\n",
    "# model = AutoEncoder(shape_data = (3,32,136), n_kernels = [64,4], kernel_size = [3,3], maxpooling = [2,2]).to(\"cuda\")\n",
    "model = Denoiser(shape_data = (3,136,32), n_kernels = [26,183], kernel_size = [3,3], maxpooling = [2,2]).to(\"cuda\")\n",
    "summary(model, (3, 136, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 4, 136]              36\n",
      "       BatchNorm1d-2               [-1, 4, 136]               8\n",
      "              ReLU-3               [-1, 4, 136]               0\n",
      "            Conv1d-4               [-1, 5, 136]              25\n",
      "       attention2d-5               [-1, 5, 136]               0\n",
      "    Dynamic_conv2d-6           [-1, 8, 136, 32]           1,080\n",
      "       BatchNorm2d-7           [-1, 8, 136, 32]              16\n",
      "              ReLU-8           [-1, 8, 136, 32]               0\n",
      "         MaxPool2d-9            [-1, 8, 45, 10]               0\n",
      "           Conv1d-10                [-1, 4, 45]              96\n",
      "      BatchNorm1d-11                [-1, 4, 45]               8\n",
      "             ReLU-12                [-1, 4, 45]               0\n",
      "           Conv1d-13                [-1, 5, 45]              25\n",
      "      attention2d-14                [-1, 5, 45]               0\n",
      "   Dynamic_conv2d-15            [-1, 8, 45, 10]           2,880\n",
      "      BatchNorm2d-16            [-1, 8, 45, 10]              16\n",
      "             ReLU-17            [-1, 8, 45, 10]               0\n",
      "        MaxPool2d-18             [-1, 8, 15, 3]               0\n",
      "           Linear-19                  [-1, 128]          46,208\n",
      "      BatchNorm1d-20                  [-1, 128]             256\n",
      "           Linear-21                   [-1, 34]           4,386\n",
      "================================================================\n",
      "Total params: 55,040\n",
      "Trainable params: 55,040\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 0.94\n",
      "Params size (MB): 0.21\n",
      "Estimated Total Size (MB): 1.20\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Keypoint Estimator \n",
    "\n",
    "class Estimator(nn.Module):\n",
    "\n",
    "    \n",
    "    def __init__(self, shape_data,  \n",
    "                dropout = None,\n",
    "                kernel_size = [3, 3, 3,3,3],\n",
    "                n_kernels =[8, 8, 8,8,8],   \n",
    "                num_layers = 2,  \n",
    "                pad = [1, 1, 1,1,1], #fix la 1,k doi \n",
    "                stride = [1, 1, 1,1,1], #fix la 1, k doi                              \n",
    "                maxPooling = [3,3,2,2,2],\n",
    "                n_basis_kernels = 5, \n",
    "                temperature = 31,\n",
    "                d_linear = 128,\n",
    "                pool_dim = 'time'): \n",
    "        super(Estimator, self).__init__()\n",
    "        \n",
    "        self.num_layers  = num_layers # no. dcnn layers \n",
    "        # self.est_n_input_ch = est_n_input_ch  # no. channels\n",
    "        self.shape_data = shape_data\n",
    "        self.dropout = dropout\n",
    "        self.kernel_size = kernel_size # kernel size\n",
    "        self.n_kernels = n_kernels  # no. filters for each conv layer\n",
    "        self.pad = pad\n",
    "        self.stride = stride\n",
    "        self.maxPooling = maxPooling   # pooling dimensions for each poooling layers \n",
    "        self.n_basis_kernels = n_basis_kernels  # no. kernels\n",
    "        \n",
    "        self.temperature = temperature\n",
    "        self.pool_dim = pool_dim # dimension for pooling\n",
    "        self.d_linear = d_linear\n",
    "        # self.est_n_filt_last = est_kernel_size[-1]\n",
    "\n",
    "        \n",
    "        self.h_conv = [0]*self.num_layers\n",
    "        self.w_conv = [0]*self.num_layers\n",
    "        self.h_pool = [0]*self.num_layers\n",
    "        self.w_pool = [0]*self.num_layers\n",
    "        in_dim = [0]*self.num_layers\n",
    "        out_dim = [0]*self.num_layers\n",
    "\n",
    "\n",
    "        cnn = nn.Sequential()\n",
    "\n",
    "        def conv(i, dropout=None):\n",
    "            in_dim[i] = self.shape_data[0] if i == 0 else self.n_kernels[i-1] #kenh dau vao cua conv\n",
    "            out_dim[i] = self.n_kernels[i] #kenh dau ra cua conv \n",
    "\n",
    "            cnn.add_module( \"conv{0}\".format(i),\n",
    "                            Dynamic_conv2d(in_dim[i],\n",
    "                                           out_dim[i],\n",
    "                                           self.kernel_size[i],\n",
    "                                           self.stride[i],\n",
    "                                           self.pad[i], \n",
    "                                           n_basis_kernels = self.n_basis_kernels, \n",
    "                                           temperature=self.temperature, \n",
    "                                           pool_dim=self.pool_dim)\n",
    "                            ) \n",
    "\n",
    "            \n",
    "            cnn.add_module(\"batchNorm{0}\".format(i), \n",
    "                           nn.BatchNorm2d(out_dim[i], momentum = 0.99)\n",
    "                           )\n",
    "                \n",
    "            cnn.add_module(\"activ{0}\".format(i), \n",
    "                           nn.ReLU())\n",
    "            \n",
    "            if dropout is not None: \n",
    "                cnn.add_module(\"dropout{0}\".format(i),\n",
    "                               nn.Dropout(dropout))\n",
    "                 \n",
    "            cnn.add_module(\"pooling{0}\".format(i), \n",
    "                           nn.MaxPool2d(self.maxPooling[i]))\n",
    "            \n",
    "            if i == 0:\n",
    "                self.h_conv[0] = int((self.shape_data[1] - self.kernel_size[0] + 3 ))\n",
    "                self.w_conv[0] = int((self.shape_data[2] - self.kernel_size[0] + 3)) \n",
    "\n",
    "                self.h_pool[0] = int((self.h_conv[0] - self.maxPooling[0])/self.maxPooling[0] + 1)\n",
    "                self.w_pool[0] = int((self.w_conv[0] - self.maxPooling[0])/self.maxPooling[0] + 1)\n",
    "            \n",
    "            else:\n",
    "                self.h_conv[i] = int((self.h_pool[i-1] - self.kernel_size[i] + 3 ))\n",
    "                self.w_conv[i] = int((self.w_pool[i-1] - self.kernel_size[i] + 3 ))\n",
    "                \n",
    "                self.h_pool[i] = int((self.h_conv[i] - self.maxPooling[i])/self.maxPooling[i] + 1)\n",
    "                self.w_pool[i] = int((self.w_conv[i] - self.maxPooling[i])/self.maxPooling[i] + 1)\n",
    "        \n",
    "        \n",
    "        for i in range(self.num_layers):  \n",
    "            conv(i, dropout= self.dropout)       \n",
    "        self.cnn = cnn\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features= out_dim[self.num_layers-1]*self.h_pool[self.num_layers-1]*self.w_pool[self.num_layers-1], out_features= self.d_linear)\n",
    "        self.batch_norm = nn.BatchNorm1d(num_features=self.d_linear)\n",
    "        self.fc2 = nn.Linear(in_features=self.d_linear, out_features=34)\n",
    "        #self.drop = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):  # x size : [batch, channel, frames, freqs] 32, 3, 10,114   ```` 32,136 \n",
    "        batch = x.shape[0]\n",
    "        # print(x.shape)\n",
    "        \n",
    "        x = self.cnn(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # print(x.shape)\n",
    "        x = self.fc1(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        # x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x.reshape(batch, 17, 2)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Estimator(shape_data = (3,136,32)).to(\"cuda\")\n",
    "\n",
    "summary(model, (3, 136, 32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 26, 136, 32]             728\n",
      "       BatchNorm2d-2          [-1, 26, 136, 32]              52\n",
      "              ReLU-3          [-1, 26, 136, 32]               0\n",
      "         MaxPool2d-4           [-1, 26, 68, 16]               0\n",
      "            Conv2d-5          [-1, 183, 68, 16]          43,005\n",
      "       BatchNorm2d-6          [-1, 183, 68, 16]             366\n",
      "              ReLU-7          [-1, 183, 68, 16]               0\n",
      "         MaxPool2d-8           [-1, 183, 34, 8]               0\n",
      "           Encoder-9           [-1, 183, 34, 8]               0\n",
      "           Conv1d-10               [-1, 45, 35]          16,470\n",
      "      BatchNorm1d-11               [-1, 45, 35]              90\n",
      "             ReLU-12               [-1, 45, 35]               0\n",
      "           Conv1d-13               [-1, 16, 35]             736\n",
      "      attention2d-14               [-1, 16, 35]               0\n",
      "   Dynamic_conv2d-15            [-1, 16, 35, 9]         187,392\n",
      "      BatchNorm2d-16            [-1, 16, 35, 9]              32\n",
      "             ReLU-17            [-1, 16, 35, 9]               0\n",
      "          Dropout-18            [-1, 16, 35, 9]               0\n",
      "        MaxPool2d-19            [-1, 16, 11, 3]               0\n",
      "           Conv1d-20                [-1, 4, 12]             128\n",
      "      BatchNorm1d-21                [-1, 4, 12]               8\n",
      "             ReLU-22                [-1, 4, 12]               0\n",
      "           Conv1d-23               [-1, 16, 12]              80\n",
      "      attention2d-24               [-1, 16, 12]               0\n",
      "   Dynamic_conv2d-25            [-1, 16, 12, 4]          16,384\n",
      "      BatchNorm2d-26            [-1, 16, 12, 4]              32\n",
      "             ReLU-27            [-1, 16, 12, 4]               0\n",
      "          Dropout-28            [-1, 16, 12, 4]               0\n",
      "        MaxPool2d-29             [-1, 16, 4, 1]               0\n",
      "           Conv1d-30                 [-1, 4, 5]             128\n",
      "      BatchNorm1d-31                 [-1, 4, 5]               8\n",
      "             ReLU-32                 [-1, 4, 5]               0\n",
      "           Conv1d-33                [-1, 16, 5]              80\n",
      "      attention2d-34                [-1, 16, 5]               0\n",
      "   Dynamic_conv2d-35             [-1, 16, 5, 2]          16,384\n",
      "      BatchNorm2d-36             [-1, 16, 5, 2]              32\n",
      "             ReLU-37             [-1, 16, 5, 2]               0\n",
      "          Dropout-38             [-1, 16, 5, 2]               0\n",
      "        MaxPool2d-39             [-1, 16, 2, 1]               0\n",
      "           Conv1d-40                 [-1, 4, 3]             128\n",
      "      BatchNorm1d-41                 [-1, 4, 3]               8\n",
      "             ReLU-42                 [-1, 4, 3]               0\n",
      "           Conv1d-43                [-1, 16, 3]              80\n",
      "      attention2d-44                [-1, 16, 3]               0\n",
      "   Dynamic_conv2d-45             [-1, 16, 3, 2]          16,384\n",
      "      BatchNorm2d-46             [-1, 16, 3, 2]              32\n",
      "             ReLU-47             [-1, 16, 3, 2]               0\n",
      "          Dropout-48             [-1, 16, 3, 2]               0\n",
      "        MaxPool2d-49             [-1, 16, 1, 1]               0\n",
      "           Conv1d-50                 [-1, 4, 2]             128\n",
      "      BatchNorm1d-51                 [-1, 4, 2]               8\n",
      "             ReLU-52                 [-1, 4, 2]               0\n",
      "           Conv1d-53                [-1, 16, 2]              80\n",
      "      attention2d-54                [-1, 16, 2]               0\n",
      "   Dynamic_conv2d-55             [-1, 16, 2, 2]          16,384\n",
      "      BatchNorm2d-56             [-1, 16, 2, 2]              32\n",
      "             ReLU-57             [-1, 16, 2, 2]               0\n",
      "          Dropout-58             [-1, 16, 2, 2]               0\n",
      "        MaxPool2d-59             [-1, 16, 1, 1]               0\n",
      "           Linear-60                  [-1, 256]           4,352\n",
      "      BatchNorm1d-61                  [-1, 256]             512\n",
      "           Linear-62                   [-1, 34]           8,738\n",
      "        Estimator-63                [-1, 17, 2]               0\n",
      "================================================================\n",
      "Total params: 329,001\n",
      "Trainable params: 329,001\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 8.37\n",
      "Params size (MB): 1.26\n",
      "Estimated Total Size (MB): 9.68\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, denoiser, predictor):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        # Denoiser\n",
    "        self.denoiser = denoiser\n",
    "        # FD CNN\n",
    "        self.predictor = predictor\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            encoded = self.denoiser(x)\n",
    "        output = self.predictor(encoded)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "AE = Denoiser(shape_data = (3,136,32), n_kernels = [26,183], kernel_size = [3,3], maxpooling = [2,2])\n",
    "\n",
    "CNN_input_shape = (AE.encoder.n_kernels[-1], AE.encoder.h_pool2, AE.encoder.w_pool2)\n",
    "\n",
    "CNN = Estimator(shape_data=CNN_input_shape, \n",
    "                              dropout=0.1,\n",
    "                              n_basis_kernels=16,\n",
    "                              kernel_size=[2,2,2,2,2],\n",
    "                              n_kernels=[16,16,16,16,16],\n",
    "                              num_layers= 5,\n",
    "                              pad=[1,1,1,1,1,1],\n",
    "                              stride = [1,1,1,1,1],\n",
    "                              maxPooling= (3,3,2,2,2),\n",
    "                              temperature=30, \n",
    "                              pool_dim='time',\n",
    "                              d_linear = 256\n",
    "                              )\n",
    "\n",
    "model = CombinedModel(AE.encoder, CNN)\n",
    "model = model.to(device)\n",
    "summary(model, (3, 136, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Denoise_Trainer:\n",
    "    def __init__(self, model, train_loader, val_loader, test_loader, criterion, optimizer,\n",
    "                 scheduler, model_save_path=\"checkpoints\"):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.model_save_path = model_save_path\n",
    "        self.metric = dict()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.train_epoch_idx = 0\n",
    "        self.val_epoch_idx = 0\n",
    "\n",
    "    def train_epoch(self):\n",
    "        # print(f\"Training Denoiser. Epoch: {self.train_epoch_idx}\")\n",
    "        self.metric[self.train_epoch_idx] = dict()\n",
    "        self.model.train()\n",
    "        losses = []\n",
    "        \n",
    "        for iter, (data, label) in enumerate(self.train_loader):\n",
    "            data = data.to(self.device)\n",
    "            label = label.to(self.device)\n",
    "            predict = self.model(data)\n",
    "            loss = self.criterion(predict, label)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            # print(f\"Iter {iter + self.train_epoch_idx * len(self.train_loader)}: MSE - {losses[-1]}\")\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        self.metric[self.train_epoch_idx][\"denoiser_train_loss\"] = sum(losses) / len(losses)\n",
    "        \n",
    "        self.train_epoch_idx += 1\n",
    "\n",
    "    def val_epoch(self):\n",
    "        # print(f\"Validating Denoiser. Epoch: {self.val_epoch_idx}\")\n",
    "        self.metric[self.train_epoch_idx] = dict()\n",
    "        self.model.eval()\n",
    "        losses = []\n",
    "        for data, label in self.val_loader:\n",
    "            data = data.to(self.device)\n",
    "            label = label.to(self.device)\n",
    "            with torch.no_grad():\n",
    "                predict = self.model(data)\n",
    "            loss = self.criterion(predict, label)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        self.metric[self.val_epoch_idx][\"denoiser_val_loss\"] = sum(losses) / len(losses)\n",
    "        \n",
    "        # print(f\"Val loss: {sum(losses) / len(losses)}\")\n",
    "        if self.val_epoch_idx == 0 or \\\n",
    "                self.metric[self.val_epoch_idx][\"denoiser_val_loss\"] < self.metric[self.val_epoch_idx - 1][\"denoiser_val_loss\"]:\n",
    "            self.save_model()\n",
    "            # print(f\"Denoiser Model is saved at epoch {self.val_epoch_idx}\")\n",
    "        self.val_epoch_idx += 1\n",
    "\n",
    "    def test_epoch(self):\n",
    "        # print(f\"Testing Denoiser\")\n",
    "        # self.model.load_state_dict(torch.load(\"/home/nxhoang/Work/HPE-VinUni/src/model/checkpoints/model_best.pth\")['model_state_dict'])\n",
    "        self.model.eval()\n",
    "        losses = []\n",
    "        for data, label in tqdm(self.test_loader):\n",
    "            data = data.to(self.device)\n",
    "            label = label.to(self.device)\n",
    "            with torch.no_grad():\n",
    "                predict = self.model(data)\n",
    "            loss = self.criterion(predict, label)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        self.metric[\"test\"] = sum(losses) / len(losses)\n",
    "        \n",
    "        # print(f\"Denoiser test result: {self.metric['test']}\")\n",
    "\n",
    "    def save_model(self):\n",
    "        state_dict = dict()\n",
    "        state_dict[\"model_state_dict\"] = self.model.state_dict()\n",
    "        state_dict[\"optimizer_state_dict\"] = self.optimizer.state_dict()\n",
    "        state_dict[\"train_loss_history\"] = torch.tensor([self.metric[i][\"denoiser_train_loss\"] for i in range(self.train_epoch_idx)])\n",
    "        state_dict[\"val_loss_history\"] = torch.tensor([self.metric[i][\"denoiser_val_loss\"] for i in range(self.val_epoch_idx)])\n",
    "\n",
    "        save_path = os.path.join(self.model_save_path, f\"model_best.pth\")\n",
    "        torch.save(state_dict, save_path)\n",
    "\n",
    "\n",
    "class Estimastor_Trainer:\n",
    "    def __init__(self, model, train_loader, val_loader, test_loader, criterion, optimizer,\n",
    "                 scheduler = None, model_save_path=\"checkpoints\"):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        # self.scheduler = scheduler\n",
    "        self.model_save_path = model_save_path\n",
    "        self.metric = dict()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.train_epoch_idx = 0\n",
    "        self.val_epoch_idx = 0\n",
    "        self.min_val_loss = 9999\n",
    "\n",
    "    def train_epoch(self):\n",
    "        # print(f\"Training Estimator.  Epoch {self.train_epoch_idx}\")\n",
    "        self.metric[self.train_epoch_idx] = dict()\n",
    "        self.model.train()\n",
    "        losses = []\n",
    "\n",
    "        for iter, (data, gt) in enumerate(self.train_loader):\n",
    "            # print(data.shape)\n",
    "            data = np.transpose(data, (0, 1, 3, 2))\n",
    "            # print('data_shape', data.shape)\n",
    "            data = data.to(self.device)\n",
    "            confidence = gt[:, :, 2:].to(self.device)\n",
    "            # print('shape confidence', confidence.shape)\n",
    "            label = gt[:, :, 0:2].to(self.device)\n",
    "            # print('shape label', label.shape)\n",
    "            predict = self.model(data)\n",
    "            # print('shape predict', predict.shape)\n",
    "\n",
    "            loss = self.criterion(torch.mul(predict, confidence), torch.mul(label, confidence)) / 32\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            # print(f\"Iter {iter + self.train_epoch_idx * len(self.train_loader)}: MSE - {losses[-1]}\")\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        # self.scheduler.step()\n",
    "\n",
    "        self.metric[self.train_epoch_idx][\"train_loss\"] = sum(losses) / len(losses)\n",
    "         \n",
    "        self.train_epoch_idx += 1\n",
    "\n",
    "    def val_epoch(self):\n",
    "        # print(f\"Validating Estimator. Epoch {self.val_epoch_idx}\")\n",
    "        self.metric[self.train_epoch_idx] = dict()\n",
    "        self.model.eval()\n",
    "\n",
    "        pck_50_iter = []\n",
    "        pck_40_iter = []\n",
    "        pck_30_iter = []\n",
    "        pck_20_iter = []\n",
    "        pck_10_iter = []\n",
    "        pck_5_iter = []\n",
    "\n",
    "        error_iter = []\n",
    "\n",
    "\n",
    "        losses = []\n",
    "        for data, gt in self.val_loader:\n",
    "            data = np.transpose(data, (0, 1, 3, 2)) # [batch size, channels, freq, time]\n",
    "            data = data.to(self.device)\n",
    "            label = gt[:, :, 0:2].to(self.device) #xy_keypoint\n",
    "\n",
    "            confidence = gt[:, :, 2:3].to(self.device)\n",
    "            with torch.no_grad():\n",
    "                predict = self.model(data)\n",
    "            loss = self.criterion(torch.mul(confidence, predict), torch.mul(confidence, label))\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            predict = predict.cpu()\n",
    "            label = label.cpu()\n",
    "\n",
    "            error_iter.append(calculate_error(predict,label))\n",
    "\n",
    "\n",
    "            predict = torch.transpose(predict, 1, 2)\n",
    "            label = torch.transpose(label, 1, 2)\n",
    "\n",
    "            pck_50_iter.append(compute_pck_pckh(predict, label, 0.5))\n",
    "            pck_40_iter.append(compute_pck_pckh(predict, label, 0.4))\n",
    "            pck_30_iter.append(compute_pck_pckh(predict, label, 0.3))\n",
    "            pck_20_iter.append(compute_pck_pckh(predict, label, 0.2))\n",
    "            pck_10_iter.append(compute_pck_pckh(predict, label, 0.1))\n",
    "            pck_5_iter.append(compute_pck_pckh(predict, label, 0.05))\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "        error = np.mean(error_iter,0)*1000   \n",
    "        self.metric[self.val_epoch_idx][\"val loss\"] = sum(losses) / len(losses)\n",
    "        self.metric[self.val_epoch_idx][\"pck_50\"] = sum(pck_50_iter) / len(pck_50_iter)\n",
    "        self.metric[self.val_epoch_idx][\"pck_40\"] = sum(pck_40_iter) / len(pck_40_iter)\n",
    "        self.metric[self.val_epoch_idx][\"pck_30\"] = sum(pck_30_iter) / len(pck_30_iter)\n",
    "        self.metric[self.val_epoch_idx][\"pck_20\"] = sum(pck_20_iter) / len(pck_20_iter)\n",
    "        self.metric[self.val_epoch_idx][\"pck_10\"] = sum(pck_10_iter) / len(pck_10_iter)\n",
    "        self.metric[self.val_epoch_idx][\"pck_5\"] = sum(pck_5_iter) / len(pck_5_iter)\n",
    "        self.metric[self.val_epoch_idx][\"mpjpe\"] = error[0]\n",
    "        self.metric[self.val_epoch_idx][\"pampjpe\"] = error[1]\n",
    "\n",
    "        loss_avg = sum(losses) / len(losses)\n",
    "        print(f\"Val loss: {loss_avg}\")\n",
    "        print(\"val_pck_50: \", sum(pck_50_iter) / len(pck_50_iter))\n",
    "        print(\"val_pck_40: \", sum(pck_40_iter) / len(pck_40_iter))\n",
    "        print(\"val_pck_30: \", sum(pck_30_iter) / len(pck_30_iter))\n",
    "        print(\"val_pck_20: \", sum(pck_20_iter) / len(pck_20_iter))\n",
    "        print(\"val_pck_10: \", sum(pck_10_iter) / len(pck_10_iter))\n",
    "        print(\"val_pck_5: \", sum(pck_5_iter) / len(pck_5_iter))\n",
    "        print(\"val_mpjpe: \", error[0])\n",
    "        print(\"val_pampjpe: \", error[1])\n",
    "\n",
    "        logs = \"Val loss: \" + str(sum(losses) / len(losses)) + \", \"\n",
    "        logs += \"pck_50: \" + str(sum(pck_50_iter) / len(pck_50_iter)) + \", \"\n",
    "        logs += \"pck_40: \" + str(sum(pck_40_iter) / len(pck_40_iter)) + \", \"\n",
    "        logs += \"pck_30: \" + str(sum(pck_30_iter) / len(pck_30_iter)) + \", \"\n",
    "        logs += \"pck_20: \" + str(sum(pck_20_iter) / len(pck_20_iter)) + \", \"\n",
    "        logs += \"pck_10: \" + str(sum(pck_10_iter) / len(pck_10_iter)) + \", \"\n",
    "        logs += \"pck_5: \" + str(sum(pck_5_iter) / len(pck_5_iter)) + \"\\n\"\n",
    "        \n",
    "        # with open(\"/home/nxhoang/Work/HPE/src/model/logs/combined_model.txt\", \"a\") as f:\n",
    "        \n",
    "        #     f.write(logs)\n",
    "\n",
    "        if self.val_epoch_idx == 0 or \\\n",
    "                self.metric[self.val_epoch_idx][\"val loss\"] < self.min_val_loss:\n",
    "            self.min_val_loss = self.metric[self.val_epoch_idx][\"val loss\"]\n",
    "            self.save_model()\n",
    "            # print(f\"Estimator Model is saved at epoch {self.val_epoch_idx}\")\n",
    "        self.val_epoch_idx += 1\n",
    "\n",
    "    def test_epoch(self):\n",
    "        # print(f\"Estmator Testing\")\n",
    "        self.model.load_state_dict(torch.load(\"/home/nxhoang/Work/HPE-VinUni/src/model/checkpoints/model_best.pth\")['model_state_dict'])\n",
    "        self.model.eval()\n",
    "        pck_50_iter = []\n",
    "        pck_40_iter = []\n",
    "        pck_30_iter = []\n",
    "        pck_20_iter = []\n",
    "        pck_10_iter = []\n",
    "        pck_5_iter = []\n",
    "        error_iter = []\n",
    "        losses = []\n",
    "        for data, gt in tqdm(self.test_loader):\n",
    "            data = np.transpose(data, (0, 1, 3, 2))  # [batch size, channels, freq, time]\n",
    "            data = data.to(self.device)\n",
    "            label = gt[:, :, 0:2].to(self.device)\n",
    "            confidence = gt[:, :, 2:].to(self.device)\n",
    "            with torch.no_grad():\n",
    "                predict = self.model(data)\n",
    "            loss = self.criterion(torch.mul(predict, confidence), torch.mul(label, confidence))\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            predict = predict.cpu()\n",
    "            label = label.cpu()\n",
    "            error_iter.append(calculate_error(predict,label))\n",
    "\n",
    "\n",
    "            predict = torch.transpose(predict, 1, 2)\n",
    "            label = torch.transpose(label, 1, 2)\n",
    "\n",
    "            pck_50_iter.append(compute_pck_pckh(predict, label, 0.5))\n",
    "            pck_40_iter.append(compute_pck_pckh(predict, label, 0.4))\n",
    "            pck_30_iter.append(compute_pck_pckh(predict, label, 0.3))\n",
    "            pck_20_iter.append(compute_pck_pckh(predict, label, 0.2))\n",
    "            pck_10_iter.append(compute_pck_pckh(predict, label, 0.1))\n",
    "            pck_5_iter.append(compute_pck_pckh(predict, label, 0.05))\n",
    "\n",
    "           \n",
    "\n",
    "        error = np.mean(error_iter,0)*1000\n",
    "        self.metric[\"test\"] = dict()\n",
    "        self.metric[\"test\"][\"loss\"] = sum(losses) / len(losses)\n",
    "        self.metric[\"test\"][\"pck_50\"] = sum(pck_50_iter) / len(pck_50_iter)\n",
    "        self.metric[\"test\"][\"pck_40\"] = sum(pck_40_iter) / len(pck_40_iter)\n",
    "        self.metric[\"test\"][\"pck_30\"] = sum(pck_30_iter) / len(pck_30_iter)\n",
    "        self.metric[\"test\"][\"pck_20\"] = sum(pck_20_iter) / len(pck_20_iter)\n",
    "        self.metric[\"test\"][\"pck_10\"] = sum(pck_10_iter) / len(pck_10_iter)\n",
    "        self.metric[\"test\"][\"pck_5\"] = sum(pck_5_iter) / len(pck_5_iter)\n",
    "        self.metric[\"test\"][\"mpjpe_mean\"] = error[0]\n",
    "        self.metric[\"test\"][\"pampjpe_mean\"] = error[1]\n",
    "        \n",
    "\n",
    "    def save_model(self):\n",
    "        state_dict = dict()\n",
    "        state_dict[\"model_state_dict\"] = self.model.state_dict()\n",
    "        state_dict[\"optimizer_state_dict\"] = self.optimizer.state_dict()\n",
    "        state_dict[\"train_loss_history\"] = torch.tensor([self.metric[i][\"train_loss\"] for i in range(self.train_epoch_idx)])\n",
    "        state_dict[\"val_loss_history\"] = torch.tensor([self.metric[i][\"val loss\"] for i in range(self.val_epoch_idx)])\n",
    "        state_dict[\"pck_50\"] = self.metric[self.val_epoch_idx][\"pck_50\"]\n",
    "        state_dict[\"pck_40\"] = self.metric[self.val_epoch_idx][\"pck_40\"]\n",
    "        state_dict[\"pck_30\"] = self.metric[self.val_epoch_idx][\"pck_30\"]\n",
    "        state_dict[\"pck_20\"] = self.metric[self.val_epoch_idx][\"pck_20\"]\n",
    "        state_dict[\"pck_10\"] = self.metric[self.val_epoch_idx][\"pck_10\"]\n",
    "        state_dict[\"pck_5\"] = self.metric[self.val_epoch_idx][\"pck_5\"]\n",
    "        state_dict[\"mpjpe\"] = self.metric[self.val_epoch_idx][\"mpjpe\"]\n",
    "        state_dict[\"pampjpe\"] = self.metric[self.val_epoch_idx][\"pampjpe\"]\n",
    "        save_path = os.path.join(self.model_save_path, f\"model_best.pth\")\n",
    "        torch.save(state_dict, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/nxhoang/Work/HPE-VinUni/src/model/configs/config_withoutBO.yaml') as f:\n",
    "  config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_config = {'modality': 'wifi-csi',\n",
    "                        'protocol': 'protocol2',\n",
    "                        'data_unit': 'frame',\n",
    "                        'random_split': {'ratio': 0.8,\n",
    "                                         'random_seed': 42,\n",
    "                                         'train_dataset': {'split': 'training',\n",
    "                                                            'scenes': 'None',\n",
    "                                                            'subjects': 'None',\n",
    "                                                          'actions': 'all'},\n",
    "                                          'val_dataset': {'split': 'validation',\n",
    "                                                          'scenes': 'None',\n",
    "                                                          'subjects': 'None',\n",
    "                                                          'actions': 'all'}},\n",
    "                        'cross_scene_split': {'train_dataset': {'split': 'training',\n",
    "                                              'scenes': ['E01', 'E02', 'E03'],\n",
    "                                              'subjects': 'None',\n",
    "                                              'actions': 'all'},\n",
    "                                              'val_dataset': {'split': 'validation',\n",
    "                                                              'scenes': ['E04'],\n",
    "                                                              'subjects': 'None',\n",
    "                                                              'actions': 'all'}},\n",
    "                        'cross_subject_split': {'train_dataset': {'split': 'training',\n",
    "                                                                  'scenes': 'None',\n",
    "                                                                  'subjects': ['S01','S02','S03','S04','S06','S07','S08','S09','S11','S12','S13','S14','S16','S17','S18','S19','S21','S22','S23','S24','S26','S27','S28','S29','S31','S32','S33','S34','S36','S37','S38','S39'],\n",
    "                                                                  'actions': 'all'},\n",
    "                                                'val_dataset': {'split': 'validation',\n",
    "                                                                'scenes': 'None',\n",
    "                                                                'subjects': ['S05', 'S10', 'S15', 'S20', 'S25', 'S30', 'S35', 'S40'],\n",
    "                                                                'actions': 'all'}},\n",
    "                        'manual_split': {'train_dataset': {'split': 'training',\n",
    "                                                           'scenes': 'None',\n",
    "                                                           'subjects': ['S01','S02','S03','S04','S05','S06','S07','S08','S09','S10','S11','S12','S13','S14','S15','S16','S17','S18','S19','S20','S21','S22','S23','S24','S25','S26','S27','S28','S29','S30','S31','S32','S33','S34','S35','S36','S37','S38','S39','S40'],\n",
    "                                                           'actions': ['A01','A02','A03','A04','A05','A06','A07','A08','A09','A10','A11','A12','A13','A14','A15','A16','A17','A18','A19','A20','A21']},\n",
    "                                          'val_dataset': {'split': 'validation',\n",
    "                                                          'scenes': 'None',\n",
    "                                                          'subjects': ['S01','S02','S03','S04','S05','S06','S07','S08','S09','S10','S11','S12','S13','S14','S15','S16','S17','S18','S19','S20','S21','S22','S23','S24','S25','S26','S27','S28','S29','S30','S31','S32','S33','S34','S35','S36','S37','S38','S39','S40'],\n",
    "                                                          'actions': ['A22', 'A23', 'A24', 'A25', 'A26', 'A27']}},\n",
    "                        'split_to_use': 'random_split',\n",
    "                        'init_rand_seed': 0,\n",
    "                        'data_root': '/home/nxhoang/Work/HPE-VinUni/Data',\n",
    "                        'AE_checkpoint': '/home/nxhoang/Work/HPE-VinUni/src/model/checkpoints/AE_model_best.pth',\n",
    "                        'combined_checkpoint': '/home/nxhoang/Work/HPE-VinUni/src/model/checkpoints/combined_model_best.pth'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = (3,136,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_train_dataset, ae_test_dataset = ae_make_dataset(other_config[\"data_root\"], other_config)\n",
    "rng_generator = torch.manual_seed(other_config['init_rand_seed'])\n",
    "train_loader = ae_make_dataloader(ae_train_dataset, is_training=True, generator=rng_generator, batch_size = config['ae_batch_size'])\n",
    "val_data, test_data = train_test_split(ae_test_dataset, test_size=0.5, random_state=41)\n",
    "val_loader = ae_make_dataloader(val_data, is_training=False, generator=rng_generator, batch_size = config['ae_batch_size'])\n",
    "test_loader = ae_make_dataloader(test_data, is_training=False, generator=rng_generator, batch_size = config['ae_batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START TRAINING DENOISER AT:  15805580368786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 23/121 [00:00<00:00, 222.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END TRAINING DENOISER AT 15854150867688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 121/121 [00:00<00:00, 225.61it/s]\n"
     ]
    }
   ],
   "source": [
    " #Initialize autoencoder denoiser\n",
    "denoiser = Denoiser(shape_data=data_shape, \n",
    "                            n_kernels=(config['ae_n_kernels_1'], config['ae_n_kernels_2']), \n",
    "                            kernel_size= [config['ae_kernel_size_1'],config['ae_kernel_size_2']], \n",
    "                            maxpooling=([config['ae_maxpooling_1'], config['ae_maxpooling_2']])\n",
    "                            ) \n",
    "denoiser.to(device)\n",
    "\n",
    "\n",
    "# Train autoencoder denoiser \n",
    "criterion_ae = nn.MSELoss().to(device)\n",
    "optimizer_ae = torch.optim.RMSprop(denoiser.parameters(), lr=config['ae_lr'], momentum=config['ae_momentum'])\n",
    "# optimizer_ae = torch.optim.Adam(denoiser.parameters(), lr=config['ae_lr'])\n",
    "        \n",
    "n_epochs_ae = config['ae_n_epochs']\n",
    "\n",
    "        \n",
    "schedule_ae = LambdaLR(optimizer_ae, lr_lambda=lambda epoch: 1 if epoch < 45 else torch.exp(-0.1))\n",
    "\n",
    "trainer_ae = Denoise_Trainer(denoiser, train_loader, val_loader, test_loader, criterion=criterion_ae,\n",
    "                                     optimizer=optimizer_ae, scheduler=schedule_ae)\n",
    "        \n",
    "print(\"START TRAINING DENOISER AT: \", time.perf_counter_ns())\n",
    "for epoch in range(n_epochs_ae):\n",
    "        trainer_ae.train_epoch()\n",
    "        trainer_ae.val_epoch()\n",
    "print(\"END TRAINING DENOISER AT\", time.perf_counter_ns())\n",
    "trainer_ae.test_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Extract Encoder part\n",
    "en_denoiser = denoiser.encoder\n",
    "en_denoiser.eval()\n",
    "for param in en_denoiser.parameters():\n",
    "    param.requires_grad = False  # Freeze parameters\n",
    "\n",
    "#================================================ Initialize estimator ======================================#\n",
    "cnn_input_shape = (en_denoiser.n_kernels[-1], en_denoiser.h_pool2, en_denoiser.w_pool2)\n",
    "        \n",
    "estimator = Estimator(shape_data=cnn_input_shape, \n",
    "                              dropout=config['est_dropout'],\n",
    "                              n_basis_kernels=config['est_n_basis_kernels'],\n",
    "                              kernel_size=(config['est_kernel_size_1'], config['est_kernel_size_2'], config['est_kernel_size_3']),\n",
    "                              n_kernels=(config['est_n_kernels_1'], config['est_n_kernels_2'], config['est_n_kernels_3']),\n",
    "                              num_layers=config['est_num_layers'],\n",
    "                              pad=[1,1,1,1,1],\n",
    "                              stride = [1,1,1,1,1],\n",
    "                              maxPooling= (config['est_maxpooling_1'],  config['est_maxpooling_2'], config['est_maxpooling_3']),\n",
    "                              temperature=config['est_temperature'], \n",
    "                              pool_dim='time',\n",
    "                              d_linear = config['est_d_hidden']\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START TRAINING ESTIMATOR AT:  15868821974072\n",
      "Val loss: 0.23916999287292606\n",
      "val_pck_50:  80.09322837741651\n",
      "val_pck_40:  71.03313917780227\n",
      "val_pck_30:  56.74216920374707\n",
      "val_pck_20:  35.467932049869134\n",
      "val_pck_10:  11.804580951232953\n",
      "val_pck_5:  3.16953881962621\n",
      "val_mpjpe:  178.76235603309067\n",
      "val_pampjpe:  90.32659576216138\n",
      "Val loss: 0.21971766015545266\n",
      "val_pck_50:  81.49221010125359\n",
      "val_pck_40:  72.9345862320338\n",
      "val_pck_30:  59.525621211599386\n",
      "val_pck_20:  39.13606169926986\n",
      "val_pck_10:  13.63734530697525\n",
      "val_pck_5:  3.630173893327824\n",
      "val_mpjpe:  170.19553189394904\n",
      "val_pampjpe:  88.49437643876477\n"
     ]
    }
   ],
   "source": [
    "# Initialize a combined model\n",
    "combined_model = CombinedModel(en_denoiser, estimator).to(device)\n",
    "\n",
    "est_train_dataset, est_test_dataset = est_make_dataset(other_config[\"data_root\"], other_config)\n",
    "rng_generator1 = torch.manual_seed(other_config['init_rand_seed'])\n",
    "train_loader1 = est_make_dataloader(est_train_dataset, is_training=True, generator=rng_generator1,\n",
    "                                                 batch_size = config['est_batch_size'])\n",
    "val_data1, test_data1 = train_test_split(est_test_dataset, test_size=0.5, random_state=41)\n",
    "val_loader1 = est_make_dataloader(val_data1, is_training=False, generator=rng_generator1,\n",
    "                                               batch_size = config['est_batch_size'])\n",
    "test_loader1 = est_make_dataloader(test_data1, is_training=False, generator=rng_generator1,\n",
    "                                                batch_size = config['est_batch_size'])\n",
    "\n",
    "        # Training combined_model with Encoder parameters being frozen\n",
    "criterion_cb = nn.MSELoss().to(device)\n",
    "        # optimizer_cb = torch.optim.SGD(combined_model.parameters(), lr=config['est_lr'], momentum=config['est_momentum'])\n",
    "optimizer_cb = torch.optim.Adam(combined_model.parameters(), lr=config['est_lr'])\n",
    "\n",
    "n_epochs_cb = config[\"est_n_epochs\"]\n",
    "      \n",
    "\n",
    "\n",
    "trainer_cb = Estimastor_Trainer(combined_model, train_loader1, val_loader1, test_loader1, criterion=criterion_cb,\n",
    "                                        optimizer=optimizer_cb, scheduler=None)\n",
    "        \n",
    "print(\"START TRAINING ESTIMATOR AT: \", time.perf_counter_ns())\n",
    "for epoch in range(n_epochs_cb):\n",
    "        trainer_cb.train_epoch()\n",
    "        trainer_cb.val_epoch()\n",
    "print(\"END TRAINING ESTIMATOR AT: \", time.perf_counter_ns())    \n",
    "trainer_cb.test_epoch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
