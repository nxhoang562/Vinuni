
data_shape
START TRAINING DENOISER AT:  2439080851058
Training Denoiser. Epoch: 0
Iter 0: MSE - 0.37257206439971924
Iter 1: MSE - 0.4228820204734802
Iter 2: MSE - 0.25696009397506714
Iter 3: MSE - 0.22843357920646667
Iter 4: MSE - 0.19512315094470978
Iter 5: MSE - 0.1627773642539978
Iter 6: MSE - 0.14409980177879333
Iter 7: MSE - 0.13270573318004608
Iter 8: MSE - 0.12191080302000046
Iter 9: MSE - 0.10599798709154129
Iter 10: MSE - 0.0925901010632515
Iter 11: MSE - 0.08735060691833496
Iter 12: MSE - 0.07675627619028091
Iter 13: MSE - 0.07447955757379532
Iter 14: MSE - 0.06874488294124603
Iter 15: MSE - 0.06617219746112823
Iter 16: MSE - 0.06076621264219284
Iter 17: MSE - 0.05655227228999138
Iter 18: MSE - 0.05513783171772957
Iter 19: MSE - 0.050252821296453476
Iter 20: MSE - 0.04764697328209877
Iter 21: MSE - 0.0456523634493351
Iter 22: MSE - 0.04339350759983063
Iter 23: MSE - 0.03870955854654312
Iter 24: MSE - 0.03656843677163124
Iter 25: MSE - 0.035648588091135025
Iter 26: MSE - 0.03494107723236084
Iter 27: MSE - 0.03322981297969818
Iter 28: MSE - 0.029277686029672623
Iter 29: MSE - 0.03156501054763794
Iter 30: MSE - 0.02677682228386402
Iter 31: MSE - 0.027332203462719917
Iter 32: MSE - 0.02476637065410614
Iter 33: MSE - 0.022349057719111443
Iter 34: MSE - 0.02309853956103325
Iter 35: MSE - 0.020387547090649605
Iter 36: MSE - 0.02110990509390831
Iter 37: MSE - 0.018406830728054047
Iter 38: MSE - 0.0172828771173954
Iter 39: MSE - 0.019657539203763008
Iter 40: MSE - 0.016126137226819992
Iter 41: MSE - 0.019386418163776398
Iter 42: MSE - 0.014553233049809933
Iter 43: MSE - 0.015409535728394985
Iter 44: MSE - 0.016305629163980484
Iter 45: MSE - 0.013512241654098034
Iter 46: MSE - 0.021951764822006226
Iter 47: MSE - 0.012886141426861286
Iter 48: MSE - 0.015645191073417664
Iter 49: MSE - 0.015203889459371567
Iter 50: MSE - 0.011269154027104378
Iter 51: MSE - 0.01650426536798477
Iter 52: MSE - 0.013802926056087017
Iter 53: MSE - 0.009829928167164326
Iter 54: MSE - 0.01460243295878172
Iter 55: MSE - 0.01370626874268055
Iter 56: MSE - 0.009386273100972176
Iter 57: MSE - 0.011091964319348335
Iter 58: MSE - 0.010707724839448929
Iter 59: MSE - 0.008904602378606796
Iter 60: MSE - 0.009825254790484905
Iter 61: MSE - 0.008588118478655815
Iter 62: MSE - 0.011323445476591587
Iter 63: MSE - 0.008308157324790955
Iter 64: MSE - 0.011911764740943909
Iter 65: MSE - 0.009154384024441242
Iter 66: MSE - 0.007831558585166931
Iter 67: MSE - 0.010778319090604782
Iter 68: MSE - 0.010635146871209145
Iter 69: MSE - 0.007373380940407515
Iter 70: MSE - 0.0075513627380132675
Iter 71: MSE - 0.008346408605575562
Iter 72: MSE - 0.009012862108647823
Iter 73: MSE - 0.00712463678792119
Iter 74: MSE - 0.007078602444380522
Iter 75: MSE - 0.007566812913864851
Iter 76: MSE - 0.007375461980700493
Iter 77: MSE - 0.007380452007055283
Iter 78: MSE - 0.006990375928580761
Iter 79: MSE - 0.0072146146558225155
Iter 80: MSE - 0.006328698713332415
Iter 81: MSE - 0.005908314138650894
Iter 82: MSE - 0.008226430974900723
Iter 83: MSE - 0.005732639227062464
Iter 84: MSE - 0.00577910291031003
Iter 85: MSE - 0.0055879694409668446
Iter 86: MSE - 0.0058489092625677586
Iter 87: MSE - 0.006339588202536106
Iter 88: MSE - 0.005682850256562233
Iter 89: MSE - 0.005338253919035196
Iter 90: MSE - 0.005587756633758545
Iter 91: MSE - 0.007010218221694231
Iter 92: MSE - 0.005175386089831591
Iter 93: MSE - 0.005300987046211958
Iter 94: MSE - 0.005835368763655424
Iter 95: MSE - 0.006602082867175341
Iter 96: MSE - 0.006104631815105677
Iter 97: MSE - 0.005995827727019787
Iter 98: MSE - 0.007154232822358608
Iter 99: MSE - 0.005185803398489952
Iter 100: MSE - 0.004983630031347275
Iter 101: MSE - 0.006311922799795866
Iter 102: MSE - 0.005232764407992363
Iter 103: MSE - 0.0049809967167675495
Iter 104: MSE - 0.0047229272313416
Iter 105: MSE - 0.004991663619875908
Iter 106: MSE - 0.004681714810431004
Iter 107: MSE - 0.005067441146820784
Iter 108: MSE - 0.004751013591885567
Iter 109: MSE - 0.00461888313293457
Iter 110: MSE - 0.005127286538481712
Iter 111: MSE - 0.0045716832391917706
Iter 112: MSE - 0.004481423646211624
Iter 113: MSE - 0.004257525317370892
Iter 114: MSE - 0.00447825388982892
Iter 115: MSE - 0.004239108879119158
Iter 116: MSE - 0.005563026759773493
Iter 117: MSE - 0.0044845049269497395
Iter 118: MSE - 0.004505191929638386
Iter 119: MSE - 0.005987722892314196
Iter 120: MSE - 0.004312804434448481
Iter 121: MSE - 0.004645826295018196
Iter 122: MSE - 0.005417391192167997
Iter 123: MSE - 0.004476395435631275
Iter 124: MSE - 0.004080221988260746
Iter 125: MSE - 0.004366923123598099
Iter 126: MSE - 0.004307164344936609
Iter 127: MSE - 0.004394778981804848
Iter 128: MSE - 0.004192674998193979
Iter 129: MSE - 0.00405264925211668
Iter 130: MSE - 0.004021068103611469
Iter 131: MSE - 0.003843507496640086
Iter 132: MSE - 0.0039428346790373325
Iter 133: MSE - 0.0037253492046147585
Iter 134: MSE - 0.0037738343235105276
Iter 135: MSE - 0.003872902598232031
Iter 136: MSE - 0.0038620128761976957
Iter 137: MSE - 0.0037773007061332464
Iter 138: MSE - 0.0038864603266119957
Iter 139: MSE - 0.0037311380729079247
Iter 140: MSE - 0.003947558347135782
Iter 141: MSE - 0.003890062216669321
Iter 142: MSE - 0.0036673597060143948
Iter 143: MSE - 0.003747364040464163
Iter 144: MSE - 0.0034094227012246847
Iter 145: MSE - 0.003834374016150832
Iter 146: MSE - 0.003592113731428981
Iter 147: MSE - 0.003773714182898402
Iter 148: MSE - 0.003990957047790289
Iter 149: MSE - 0.004309077747166157
Iter 150: MSE - 0.0036797127686440945
Iter 151: MSE - 0.004528870806097984
Iter 152: MSE - 0.003411108860746026
Iter 153: MSE - 0.003997732885181904
Iter 154: MSE - 0.003497438272461295
Iter 155: MSE - 0.0038269401993602514
Iter 156: MSE - 0.0036156531423330307
Iter 157: MSE - 0.003672692459076643
Iter 158: MSE - 0.003731406293809414
Iter 159: MSE - 0.0037242958787828684
Iter 160: MSE - 0.004119977355003357
Iter 161: MSE - 0.0038184344302862883
Iter 162: MSE - 0.003294345224276185
Iter 163: MSE - 0.004148507956415415
Iter 164: MSE - 0.0033823258709162474
Iter 165: MSE - 0.003280031494796276
Iter 166: MSE - 0.004412556532770395
Iter 167: MSE - 0.00330855674110353
Iter 168: MSE - 0.004072904586791992
Iter 169: MSE - 0.003387682605534792
Iter 170: MSE - 0.004061845131218433
Iter 171: MSE - 0.003957611974328756
Iter 172: MSE - 0.003274062182754278
Iter 173: MSE - 0.004121629986912012
Iter 174: MSE - 0.00356156169436872
Iter 175: MSE - 0.003539209719747305
Iter 176: MSE - 0.004340512212365866
Iter 177: MSE - 0.0034527869429439306
Iter 178: MSE - 0.003695107065141201
Iter 179: MSE - 0.003636991372331977
Iter 180: MSE - 0.003117852145805955
Iter 181: MSE - 0.0035295425914227962
Iter 182: MSE - 0.0031581255607306957
Iter 183: MSE - 0.003617025911808014
Iter 184: MSE - 0.003420435357838869
Iter 185: MSE - 0.00333867478184402
Iter 186: MSE - 0.003359500551596284
Iter 187: MSE - 0.004002295900136232
Iter 188: MSE - 0.0034813752863556147
Iter 189: MSE - 0.0034892710391432047
Iter 190: MSE - 0.00305892969481647
Iter 191: MSE - 0.0033154983539134264
Iter 192: MSE - 0.003069744212552905
Iter 193: MSE - 0.0032821029890328646
Iter 194: MSE - 0.003185172099620104
Iter 195: MSE - 0.003126099007204175
Iter 196: MSE - 0.003076462773606181
Iter 197: MSE - 0.003992774989455938
Iter 198: MSE - 0.0029204015154391527
Iter 199: MSE - 0.0030051053036004305
Iter 200: MSE - 0.004765113350003958
Iter 201: MSE - 0.0030339218210428953
Iter 202: MSE - 0.0037853093817830086
Iter 203: MSE - 0.0039883083663880825
Iter 204: MSE - 0.0030188322998583317
Iter 205: MSE - 0.0042742108926177025
Iter 206: MSE - 0.0041987658478319645
Iter 207: MSE - 0.0028841220773756504
Iter 208: MSE - 0.002968207933008671
Iter 209: MSE - 0.0038319663144648075
Iter 210: MSE - 0.004198095295578241
Iter 211: MSE - 0.0030388166196644306
Iter 212: MSE - 0.0028589556459337473
Iter 213: MSE - 0.003784151514992118
Iter 214: MSE - 0.003396594664081931
Iter 215: MSE - 0.0029581976123154163
Iter 216: MSE - 0.0031281644478440285
Iter 217: MSE - 0.0029860890936106443
Iter 218: MSE - 0.002761558163911104
Iter 219: MSE - 0.0027634440921247005
Iter 220: MSE - 0.002710292348638177
Iter 221: MSE - 0.0029380107298493385
Iter 222: MSE - 0.002851106459274888
Iter 223: MSE - 0.002908967435359955
Iter 224: MSE - 0.004054975230246782
Iter 225: MSE - 0.00338114146143198
Iter 226: MSE - 0.004460326861590147
Iter 227: MSE - 0.003566732630133629
Iter 228: MSE - 0.0030017513781785965
Iter 229: MSE - 0.0036372793838381767
Iter 230: MSE - 0.003402901813387871
Iter 231: MSE - 0.003277573036029935
Iter 232: MSE - 0.0033914651721715927
Iter 233: MSE - 0.004478765651583672
Iter 234: MSE - 0.0031196929048746824
Iter 235: MSE - 0.0029974153731018305
Iter 236: MSE - 0.003264270955696702
Iter 237: MSE - 0.005131360609084368
Iter 238: MSE - 0.0035740078892558813
Iter 239: MSE - 0.004580055363476276
Iter 240: MSE - 0.007892248220741749
Iter 241: MSE - 0.004120985511690378
Iter 242: MSE - 0.003830486675724387
Iter 243: MSE - 0.004950900096446276
Iter 244: MSE - 0.004730887245386839
Iter 245: MSE - 0.0039680590853095055
Iter 246: MSE - 0.0037893846165388823
Iter 247: MSE - 0.003845350816845894
Iter 248: MSE - 0.0038901090156286955
Iter 249: MSE - 0.004236975684762001
Iter 250: MSE - 0.0033420573454350233
Iter 251: MSE - 0.0033819577656686306
Iter 252: MSE - 0.0038110839668661356
Iter 253: MSE - 0.003271416760981083
Iter 254: MSE - 0.0032908490393310785
Iter 255: MSE - 0.0032005722168833017
Iter 256: MSE - 0.0030634934082627296
Iter 257: MSE - 0.0030502190347760916
Iter 258: MSE - 0.0031920515466481447
Validating Denoiser. Epoch: 0
Denoiser Model is saved at epoch 0
END TRAINING DENOISER----- <built-in function perf_counter_ns>
Testing Denoiser
100%|██████████| 33/33 [00:01<00:00, 21.02it/s]
/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/init.py:412: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
START TRAINING ESTIMATOR AT:  2497145277236
Training Estimator.  Epoch 0
torch.Size([64, 220, 8, 34])
Traceback (most recent call last):
  File "/tmp/ipykernel_5348/3812810853.py", line 105, in training
    trainer_cb.train_epoch()
  File "/tmp/ipykernel_5348/453035365.py", line 124, in train_epoch
    predict = self.model(data)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/tmp/ipykernel_5348/1615517668.py", line 12, in forward
    output = self.predictor(encoded)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/tmp/ipykernel_5348/3528832199.py", line 105, in forward
    x = self.cnn(x)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/container.py", line 215, in forward
    input = module(input)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/pooling.py", line 166, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/_jit_internal.py", line 488, in fn
    return if_false(*args, **kwargs)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/functional.py", line 791, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (32x3x16). Calculated output size: (32x0x2). Output size is too small