
data_shape
START TRAINING DENOISER AT:  15185605037165
Training Denoiser. Epoch: 0
Iter 0: MSE - 0.34083303809165955
Iter 1: MSE - 13.397920608520508
Iter 2: MSE - 31.015060424804688
Iter 3: MSE - 0.5076305866241455
Iter 4: MSE - 0.8557374477386475
Iter 5: MSE - 2.3705484867095947
Iter 6: MSE - 0.5025636553764343
Iter 7: MSE - 0.48987385630607605
Iter 8: MSE - 0.49764755368232727
Iter 9: MSE - 0.49765655398368835
Iter 10: MSE - 0.4885663092136383
Iter 11: MSE - 0.5024598836898804
Iter 12: MSE - 0.4970836937427521
Iter 13: MSE - 0.5016394257545471
Iter 14: MSE - 0.49723175168037415
Iter 15: MSE - 0.49395906925201416
Iter 16: MSE - 0.49025973677635193
Iter 17: MSE - 0.5011856555938721
Iter 18: MSE - 0.4992830157279968
Iter 19: MSE - 0.49327757954597473
Iter 20: MSE - 0.4927079677581787
Iter 21: MSE - 0.492035835981369
Iter 22: MSE - 0.4937213361263275
Iter 23: MSE - 0.5039739012718201
Iter 24: MSE - 0.49371227622032166
Iter 25: MSE - 0.5025560259819031
Iter 26: MSE - 0.5003191828727722
Iter 27: MSE - 0.502541720867157
Iter 28: MSE - 0.4881981611251831
Iter 29: MSE - 0.49632975459098816
Iter 30: MSE - 0.4978698790073395
Iter 31: MSE - 0.5023341178894043
Iter 32: MSE - 0.5023823976516724
Iter 33: MSE - 0.4917958080768585
Iter 34: MSE - 0.49287083745002747
Iter 35: MSE - 0.49735409021377563
Iter 36: MSE - 0.5027654767036438
Iter 37: MSE - 0.4971553683280945
Iter 38: MSE - 0.49902158975601196
Iter 39: MSE - 0.49089381098747253
Iter 40: MSE - 0.49396711587905884
Iter 41: MSE - 0.49412763118743896
Iter 42: MSE - 0.49497875571250916
Iter 43: MSE - 0.49438852071762085
Iter 44: MSE - 0.495517760515213
Iter 45: MSE - 0.5044340491294861
Iter 46: MSE - 0.49385401606559753
Iter 47: MSE - 0.49402979016304016
Iter 48: MSE - 0.4968374967575073
Iter 49: MSE - 0.49172502756118774
Iter 50: MSE - 0.49889296293258667
Iter 51: MSE - 0.49507877230644226
Iter 52: MSE - 0.49788451194763184
Iter 53: MSE - 0.4906967878341675
Iter 54: MSE - 0.4941784143447876
Iter 55: MSE - 0.4875369668006897
Iter 56: MSE - 0.4988599419593811
Iter 57: MSE - 0.5053203105926514
Iter 58: MSE - 0.49679455161094666
Iter 59: MSE - 0.5002259016036987
Iter 60: MSE - 0.4967448115348816
Iter 61: MSE - 0.49403855204582214
Iter 62: MSE - 0.4918897747993469
Iter 63: MSE - 0.501438319683075
Iter 64: MSE - 0.4966076612472534
Iter 65: MSE - 0.4866558313369751
Iter 66: MSE - 0.4941055476665497
Iter 67: MSE - 0.495632141828537
Iter 68: MSE - 0.49611321091651917
Iter 69: MSE - 0.4918932616710663
Iter 70: MSE - 0.4983619749546051
Iter 71: MSE - 0.49246007204055786
Iter 72: MSE - 0.49466773867607117
Iter 73: MSE - 0.4949724078178406
Iter 74: MSE - 0.4933376908302307
Iter 75: MSE - 0.500350832939148
Iter 76: MSE - 0.4930359423160553
Iter 77: MSE - 0.4926425516605377
Iter 78: MSE - 0.4990829527378082
Iter 79: MSE - 0.49678003787994385
Iter 80: MSE - 0.49897173047065735
Iter 81: MSE - 0.4944160580635071
Iter 82: MSE - 0.49047085642814636
Iter 83: MSE - 0.49815040826797485
Iter 84: MSE - 0.48962831497192383
Iter 85: MSE - 0.4900631010532379
Iter 86: MSE - 0.49971339106559753
Iter 87: MSE - 0.5023890137672424
Iter 88: MSE - 0.49420449137687683
Iter 89: MSE - 0.49999433755874634
Iter 90: MSE - 0.5003457069396973
Iter 91: MSE - 0.4880549907684326
Iter 92: MSE - 0.49556171894073486
Iter 93: MSE - 0.5011917948722839
Iter 94: MSE - 0.5008789896965027
Iter 95: MSE - 0.49645301699638367
Iter 96: MSE - 0.49851194024086
Iter 97: MSE - 0.4901919960975647
Iter 98: MSE - 0.49404796957969666
Iter 99: MSE - 0.4892100691795349
Iter 100: MSE - 0.495807409286499
Iter 101: MSE - 0.4830559492111206
Iter 102: MSE - 0.48880648612976074
Iter 103: MSE - 0.4934048652648926
Iter 104: MSE - 0.4993169605731964
Iter 105: MSE - 0.4865333139896393
Iter 106: MSE - 0.49863821268081665
Iter 107: MSE - 0.4999505281448364
Iter 108: MSE - 0.4987817704677582
Iter 109: MSE - 0.48811760544776917
Iter 110: MSE - 0.49249890446662903
Iter 111: MSE - 0.4951379895210266
Iter 112: MSE - 0.5072002410888672
Iter 113: MSE - 0.49595585465431213
Iter 114: MSE - 0.4934856593608856
Iter 115: MSE - 0.4960830807685852
Iter 116: MSE - 0.49501705169677734
Iter 117: MSE - 0.4982708692550659
Iter 118: MSE - 0.4932587742805481
Iter 119: MSE - 0.49642670154571533
Iter 120: MSE - 0.4950000047683716
Iter 121: MSE - 0.49549052119255066
Iter 122: MSE - 0.48949530720710754
Iter 123: MSE - 0.49730923771858215
Iter 124: MSE - 0.4954611361026764
Iter 125: MSE - 0.4993515908718109
Iter 126: MSE - 0.4849737286567688
Iter 127: MSE - 0.504856288433075
Iter 128: MSE - 0.49167847633361816
Iter 129: MSE - 0.4985819160938263
Iter 130: MSE - 0.493335098028183
Iter 131: MSE - 0.4896399974822998
Iter 132: MSE - 0.5010390281677246
Iter 133: MSE - 0.4977568984031677
Iter 134: MSE - 0.4927489757537842
Iter 135: MSE - 0.49033647775650024
Iter 136: MSE - 0.48822104930877686
Iter 137: MSE - 0.49420586228370667
Iter 138: MSE - 0.4975008964538574
Iter 139: MSE - 0.49659785628318787
Iter 140: MSE - 0.4900059700012207
Iter 141: MSE - 0.49323490262031555
Iter 142: MSE - 0.49596428871154785
Iter 143: MSE - 0.4941478669643402
Iter 144: MSE - 0.4901575446128845
Iter 145: MSE - 0.49117571115493774
Iter 146: MSE - 0.49161702394485474
Iter 147: MSE - 0.4940454959869385
Iter 148: MSE - 0.49306291341781616
Iter 149: MSE - 0.5037639141082764
Iter 150: MSE - 0.4945545494556427
Iter 151: MSE - 0.49854329228401184
Iter 152: MSE - 0.5005383491516113
Iter 153: MSE - 0.4927445352077484
Iter 154: MSE - 0.4908897578716278
Iter 155: MSE - 0.4950700104236603
Iter 156: MSE - 0.4921354353427887
Iter 157: MSE - 0.49619796872138977
Iter 158: MSE - 0.495712012052536
Iter 159: MSE - 0.5041229128837585
Iter 160: MSE - 0.4965125620365143
Iter 161: MSE - 0.49406978487968445
Iter 162: MSE - 0.5023882985115051
Iter 163: MSE - 0.49640005826950073
Iter 164: MSE - 0.49102216958999634
Iter 165: MSE - 0.4962567389011383
Iter 166: MSE - 0.49061650037765503
Iter 167: MSE - 0.5018076300621033
Iter 168: MSE - 0.49767932295799255
Iter 169: MSE - 0.49986085295677185
Iter 170: MSE - 0.4884805977344513
Iter 171: MSE - 0.4956602156162262
Iter 172: MSE - 0.49899330735206604
Iter 173: MSE - 0.5058714151382446
Iter 174: MSE - 0.49499577283859253
Iter 175: MSE - 0.4911079704761505
Iter 176: MSE - 0.49540087580680847
Iter 177: MSE - 0.49386388063430786
Iter 178: MSE - 0.49109187722206116
Iter 179: MSE - 0.50056391954422
Iter 180: MSE - 0.5009305477142334
Iter 181: MSE - 0.503915011882782
Iter 182: MSE - 0.4892759621143341
Iter 183: MSE - 0.4940031170845032
Iter 184: MSE - 0.4946959316730499
Iter 185: MSE - 0.5022900104522705
Iter 186: MSE - 0.4936996102333069
Iter 187: MSE - 0.5006662011146545
Iter 188: MSE - 0.4988074004650116
Iter 189: MSE - 0.4937116801738739
Iter 190: MSE - 0.49465861916542053
Iter 191: MSE - 0.49987316131591797
Iter 192: MSE - 0.5012885332107544
Iter 193: MSE - 0.49662116169929504
Iter 194: MSE - 0.4952300488948822
Iter 195: MSE - 0.49231892824172974
Iter 196: MSE - 0.49427512288093567
Iter 197: MSE - 0.49455270171165466
Iter 198: MSE - 0.49631205201148987
Iter 199: MSE - 0.4971497356891632
Iter 200: MSE - 0.4930931329727173
Iter 201: MSE - 0.49439316987991333
Iter 202: MSE - 0.5027322769165039
Iter 203: MSE - 0.5017062425613403
Iter 204: MSE - 0.49751389026641846
Iter 205: MSE - 0.49044862389564514
Iter 206: MSE - 0.4980712831020355
Iter 207: MSE - 0.49672144651412964
Iter 208: MSE - 0.5014926195144653
Iter 209: MSE - 0.49274417757987976
Iter 210: MSE - 0.48446252942085266
Iter 211: MSE - 0.500153124332428
Iter 212: MSE - 0.4945889115333557
Iter 213: MSE - 0.4940160810947418
Iter 214: MSE - 0.49394258856773376
Iter 215: MSE - 0.5016127824783325
Iter 216: MSE - 0.4939015805721283
Iter 217: MSE - 0.49692144989967346
Iter 218: MSE - 0.4982467591762543
Iter 219: MSE - 0.4927533268928528
Iter 220: MSE - 0.4942655563354492
Iter 221: MSE - 0.49979814887046814
Iter 222: MSE - 0.49626192450523376
Iter 223: MSE - 0.49134349822998047
Iter 224: MSE - 0.49346432089805603
Iter 225: MSE - 0.49139055609703064
Iter 226: MSE - 0.5058109164237976
Iter 227: MSE - 0.49737825989723206
Iter 228: MSE - 0.502116858959198
Iter 229: MSE - 0.4933907687664032
Iter 230: MSE - 0.4960686266422272
Iter 231: MSE - 0.49063777923583984
Iter 232: MSE - 0.4974682629108429
Iter 233: MSE - 0.4897553026676178
Iter 234: MSE - 0.49736520648002625
Iter 235: MSE - 0.49383804202079773
Iter 236: MSE - 0.5048528909683228
Iter 237: MSE - 0.4913257658481598
Iter 238: MSE - 0.4939543306827545
Iter 239: MSE - 0.49525976181030273
Iter 240: MSE - 0.5021535754203796
Iter 241: MSE - 0.4974786639213562
Iter 242: MSE - 0.4942944347858429
Iter 243: MSE - 0.4969194531440735
Iter 244: MSE - 0.48842793703079224
Iter 245: MSE - 0.4990414083003998
Iter 246: MSE - 0.489530473947525
Iter 247: MSE - 0.4919659197330475
Iter 248: MSE - 0.4989151358604431
Iter 249: MSE - 0.4932757616043091
Iter 250: MSE - 0.4932402968406677
Iter 251: MSE - 0.4959261417388916
Iter 252: MSE - 0.5056885480880737
Iter 253: MSE - 0.49378105998039246
Iter 254: MSE - 0.49126678705215454
Iter 255: MSE - 0.49943462014198303
Iter 256: MSE - 0.4996463656425476
Iter 257: MSE - 0.49845099449157715
Iter 258: MSE - 0.4976499080657959
Validating Denoiser. Epoch: 0
Denoiser Model is saved at epoch 0
END TRAINING DENOISER AT <built-in function perf_counter_ns>
Testing Denoiser
100%|██████████| 33/33 [00:01<00:00, 28.86it/s]
START TRAINING ESTIMATOR AT:  15238542079831
Training Estimator.  Epoch 0
torch.Size([64, 129, 5, 22])
Traceback (most recent call last):
  File "/tmp/ipykernel_16175/283401866.py", line 106, in training
    trainer_cb.train_epoch()
  File "/tmp/ipykernel_16175/453035365.py", line 124, in train_epoch
    predict = self.model(data)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/tmp/ipykernel_16175/179411685.py", line 12, in forward
    output = self.predictor(encoded)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/tmp/ipykernel_16175/3528832199.py", line 105, in forward
    x = self.cnn(x)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/container.py", line 215, in forward
    input = module(input)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/tmp/ipykernel_16175/1051490638.py", line 35, in forward
    softmax_attention = self.attention(x).unsqueeze(2).unsqueeze(4)    # size : [bs, n_ker, 1, freqs, 1]
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/tmp/ipykernel_16175/1051490638.py", line 105, in forward
    x = self.conv1d1(x)               #x size : [bs, hid_chan, frames]
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
RuntimeError: Calculated padded input size per channel: (3). Kernel size: (4). Kernel size can't be greater than actual input size