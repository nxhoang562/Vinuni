
data_shape
START TRAINING DENOISER AT:  2517084607738
Training Denoiser. Epoch: 0
Iter 0: MSE - 0.3883729577064514
Iter 1: MSE - 33.92661666870117
Iter 2: MSE - 167.51222229003906
Iter 3: MSE - 0.5332810878753662
Iter 4: MSE - 24.093936920166016
Iter 5: MSE - 0.49270084500312805
Iter 6: MSE - 0.4961581826210022
Iter 7: MSE - 0.49449607729911804
Iter 8: MSE - 0.48785141110420227
Iter 9: MSE - 0.4913727343082428
Iter 10: MSE - 0.5005475878715515
Iter 11: MSE - 0.4909590482711792
Iter 12: MSE - 0.49875718355178833
Iter 13: MSE - 0.495528906583786
Iter 14: MSE - 0.4981081485748291
Iter 15: MSE - 0.4913730323314667
Iter 16: MSE - 0.4959595501422882
Iter 17: MSE - 0.494245320558548
Iter 18: MSE - 0.4844808578491211
Iter 19: MSE - 0.49292802810668945
Iter 20: MSE - 0.4941213130950928
Iter 21: MSE - 0.49502918124198914
Iter 22: MSE - 0.5010095834732056
Iter 23: MSE - 0.49281930923461914
Iter 24: MSE - 0.4987182021141052
Iter 25: MSE - 0.4968758225440979
Iter 26: MSE - 0.49988287687301636
Iter 27: MSE - 0.5050947070121765
Iter 28: MSE - 0.49178674817085266
Iter 29: MSE - 0.503957211971283
Iter 30: MSE - 0.4903327524662018
Iter 31: MSE - 0.4939671754837036
Iter 32: MSE - 0.4978165924549103
Iter 33: MSE - 0.49094969034194946
Iter 34: MSE - 0.49776771664619446
Iter 35: MSE - 0.5019663572311401
Iter 36: MSE - 0.49292105436325073
Iter 37: MSE - 0.4945816397666931
Iter 38: MSE - 0.5029997229576111
Iter 39: MSE - 0.496137797832489
Iter 40: MSE - 0.4978331923484802
Iter 41: MSE - 0.49810004234313965
Iter 42: MSE - 0.49739572405815125
Iter 43: MSE - 0.4918850362300873
Iter 44: MSE - 0.4863223731517792
Iter 45: MSE - 0.48553234338760376
Iter 46: MSE - 0.4992287755012512
Iter 47: MSE - 0.4972963333129883
Iter 48: MSE - 0.49924635887145996
Iter 49: MSE - 0.486381858587265
Iter 50: MSE - 0.4898897111415863
Iter 51: MSE - 0.5015283226966858
Iter 52: MSE - 0.49456483125686646
Iter 53: MSE - 0.4936756491661072
Iter 54: MSE - 0.5032300353050232
Iter 55: MSE - 0.4927932620048523
Iter 56: MSE - 0.5016957521438599
Iter 57: MSE - 0.4962459206581116
Iter 58: MSE - 0.49323132634162903
Iter 59: MSE - 0.49858802556991577
Iter 60: MSE - 0.4992286264896393
Iter 61: MSE - 0.49534595012664795
Iter 62: MSE - 0.4884415864944458
Iter 63: MSE - 0.4902889132499695
Iter 64: MSE - 0.49713170528411865
Iter 65: MSE - 0.4894135594367981
Iter 66: MSE - 0.4909069240093231
Iter 67: MSE - 0.5030338764190674
Iter 68: MSE - 0.49137941002845764
Iter 69: MSE - 0.4994054436683655
Iter 70: MSE - 0.49779611825942993
Iter 71: MSE - 0.5017392039299011
Iter 72: MSE - 0.4975235164165497
Iter 73: MSE - 0.4930238425731659
Iter 74: MSE - 0.4987528324127197
Iter 75: MSE - 0.5005208253860474
Iter 76: MSE - 0.50015789270401
Iter 77: MSE - 0.49651196599006653
Iter 78: MSE - 0.4993877112865448
Iter 79: MSE - 0.4953356981277466
Iter 80: MSE - 0.4965735971927643
Iter 81: MSE - 0.49138471484184265
Iter 82: MSE - 0.4968319535255432
Iter 83: MSE - 0.49898481369018555
Iter 84: MSE - 0.4954444468021393
Iter 85: MSE - 0.49325504899024963
Iter 86: MSE - 0.49539807438850403
Iter 87: MSE - 0.49501025676727295
Iter 88: MSE - 0.4997732639312744
Iter 89: MSE - 0.4888130724430084
Iter 90: MSE - 0.49323564767837524
Iter 91: MSE - 0.49970003962516785
Iter 92: MSE - 0.4908941090106964
Iter 93: MSE - 0.4928366541862488
Iter 94: MSE - 0.49574604630470276
Iter 95: MSE - 0.5001680850982666
Iter 96: MSE - 0.5034984350204468
Iter 97: MSE - 0.49746203422546387
Iter 98: MSE - 0.4947558641433716
Iter 99: MSE - 0.5011492967605591
Iter 100: MSE - 0.4991190433502197
Iter 101: MSE - 0.4911019802093506
Iter 102: MSE - 0.4932423532009125
Iter 103: MSE - 0.49607759714126587
Iter 104: MSE - 0.5009890794754028
Iter 105: MSE - 0.4923730790615082
Iter 106: MSE - 0.4931117296218872
Iter 107: MSE - 0.4987417757511139
Iter 108: MSE - 0.5035079121589661
Iter 109: MSE - 0.48884764313697815
Iter 110: MSE - 0.4874485433101654
Iter 111: MSE - 0.49629414081573486
Iter 112: MSE - 0.49914121627807617
Iter 113: MSE - 0.4943613111972809
Iter 114: MSE - 0.4950534403324127
Iter 115: MSE - 0.4929754436016083
Iter 116: MSE - 0.4972880780696869
Iter 117: MSE - 0.4918983578681946
Iter 118: MSE - 0.49717020988464355
Iter 119: MSE - 0.48867061734199524
Iter 120: MSE - 0.4977797567844391
Iter 121: MSE - 0.4949549436569214
Iter 122: MSE - 0.4909514784812927
Iter 123: MSE - 0.4978694021701813
Iter 124: MSE - 0.4994257986545563
Iter 125: MSE - 0.49851876497268677
Iter 126: MSE - 0.4963459074497223
Iter 127: MSE - 0.4919477105140686
Iter 128: MSE - 0.5012018084526062
Iter 129: MSE - 0.4918391704559326
Iter 130: MSE - 0.5028247833251953
Iter 131: MSE - 0.4959021210670471
Iter 132: MSE - 0.49649423360824585
Iter 133: MSE - 0.49444422125816345
Iter 134: MSE - 0.49192848801612854
Iter 135: MSE - 0.49315840005874634
Iter 136: MSE - 0.49652954936027527
Iter 137: MSE - 0.4947008788585663
Iter 138: MSE - 0.4904734790325165
Iter 139: MSE - 0.4898183047771454
Iter 140: MSE - 0.4947473406791687
Iter 141: MSE - 0.49256840348243713
Iter 142: MSE - 0.4980980157852173
Iter 143: MSE - 0.4991874098777771
Iter 144: MSE - 0.4964076280593872
Iter 145: MSE - 0.49510958790779114
Iter 146: MSE - 0.49767863750457764
Iter 147: MSE - 0.5037917494773865
Iter 148: MSE - 0.49769264459609985
Iter 149: MSE - 0.4954817593097687
Iter 150: MSE - 0.49626627564430237
Iter 151: MSE - 0.4897497892379761
Iter 152: MSE - 0.4946451783180237
Iter 153: MSE - 0.4994507133960724
Iter 154: MSE - 0.4916991889476776
Iter 155: MSE - 0.49507907032966614
Iter 156: MSE - 0.49338749051094055
Iter 157: MSE - 0.49803784489631653
Iter 158: MSE - 0.49176543951034546
Iter 159: MSE - 0.4978688657283783
Iter 160: MSE - 0.48993629217147827
Iter 161: MSE - 0.5014219880104065
Iter 162: MSE - 0.5026968717575073
Iter 163: MSE - 0.5028833150863647
Iter 164: MSE - 0.49522125720977783
Iter 165: MSE - 0.49851202964782715
Iter 166: MSE - 0.5000424981117249
Iter 167: MSE - 0.5002340078353882
Iter 168: MSE - 0.4961130917072296
Iter 169: MSE - 0.48383408784866333
Iter 170: MSE - 0.49823200702667236
Iter 171: MSE - 0.5005492568016052
Iter 172: MSE - 0.49215564131736755
Iter 173: MSE - 0.5022734999656677
Iter 174: MSE - 0.4933985769748688
Iter 175: MSE - 0.4938780963420868
Iter 176: MSE - 0.4915942847728729
Iter 177: MSE - 0.4951431155204773
Iter 178: MSE - 0.4929349422454834
Iter 179: MSE - 0.48709601163864136
Iter 180: MSE - 0.49870219826698303
Iter 181: MSE - 0.494282603263855
Iter 182: MSE - 0.48970291018486023
Iter 183: MSE - 0.5026950836181641
Iter 184: MSE - 0.49559327960014343
Iter 185: MSE - 0.4965112507343292
Iter 186: MSE - 0.5000401735305786
Iter 187: MSE - 0.5022602081298828
Iter 188: MSE - 0.49161702394485474
Iter 189: MSE - 0.49825260043144226
Iter 190: MSE - 0.49481549859046936
Iter 191: MSE - 0.498866468667984
Iter 192: MSE - 0.49263980984687805
Iter 193: MSE - 0.49574795365333557
Iter 194: MSE - 0.49712198972702026
Iter 195: MSE - 0.4988800585269928
Iter 196: MSE - 0.49800747632980347
Iter 197: MSE - 0.49575725197792053
Iter 198: MSE - 0.4980843961238861
Iter 199: MSE - 0.4968698024749756
Iter 200: MSE - 0.4974246621131897
Iter 201: MSE - 0.49441957473754883
Iter 202: MSE - 0.5028469562530518
Iter 203: MSE - 0.4914705753326416
Iter 204: MSE - 0.49702927470207214
Iter 205: MSE - 0.49605792760849
Iter 206: MSE - 0.5002554655075073
Iter 207: MSE - 0.4996287226676941
Iter 208: MSE - 0.49186697602272034
Iter 209: MSE - 0.49499592185020447
Iter 210: MSE - 0.4960973560810089
Iter 211: MSE - 0.49478113651275635
Iter 212: MSE - 0.4899042248725891
Iter 213: MSE - 0.4954361319541931
Iter 214: MSE - 0.493695467710495
Iter 215: MSE - 0.5021854043006897
Iter 216: MSE - 0.4983278214931488
Iter 217: MSE - 0.4917820692062378
Iter 218: MSE - 0.4916759133338928
Iter 219: MSE - 0.5010741353034973
Iter 220: MSE - 0.49625056982040405
Iter 221: MSE - 0.4965828061103821
Iter 222: MSE - 0.4880135655403137
Iter 223: MSE - 0.5016080141067505
Iter 224: MSE - 0.49223971366882324
Iter 225: MSE - 0.49120745062828064
Iter 226: MSE - 0.5032479763031006
Iter 227: MSE - 0.49992725253105164
Iter 228: MSE - 0.5014451146125793
Iter 229: MSE - 0.494207501411438
Iter 230: MSE - 0.5005372762680054
Iter 231: MSE - 0.49260616302490234
Iter 232: MSE - 0.4939882457256317
Iter 233: MSE - 0.4958162307739258
Iter 234: MSE - 0.491942435503006
Iter 235: MSE - 0.49106448888778687
Iter 236: MSE - 0.5019875764846802
Iter 237: MSE - 0.49809709191322327
Iter 238: MSE - 0.4939248561859131
Iter 239: MSE - 0.5028445720672607
Iter 240: MSE - 0.491655558347702
Iter 241: MSE - 0.5001417994499207
Iter 242: MSE - 0.4941560626029968
Iter 243: MSE - 0.5014543533325195
Iter 244: MSE - 0.4928020238876343
Iter 245: MSE - 0.4896124601364136
Iter 246: MSE - 0.486689031124115
Iter 247: MSE - 0.49814966320991516
Iter 248: MSE - 0.5088014006614685
Iter 249: MSE - 0.49446001648902893
Iter 250: MSE - 0.4962286353111267
Iter 251: MSE - 0.4976961612701416
Iter 252: MSE - 0.495309442281723
Iter 253: MSE - 0.4974050521850586
Iter 254: MSE - 0.4989553391933441
Iter 255: MSE - 0.4941815435886383
Iter 256: MSE - 0.4930284023284912
Iter 257: MSE - 0.49874016642570496
Iter 258: MSE - 0.49419307708740234
Validating Denoiser. Epoch: 0
Denoiser Model is saved at epoch 0
END TRAINING DENOISER----- <built-in function perf_counter_ns>
Testing Denoiser
100%|██████████| 33/33 [00:00<00:00, 42.95it/s]
/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/init.py:412: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
START TRAINING ESTIMATOR AT:  2568714659546
Training Estimator.  Epoch 0
torch.Size([256, 62, 5, 22])
Traceback (most recent call last):
  File "/tmp/ipykernel_5348/3812810853.py", line 105, in training
    trainer_cb.train_epoch()
  File "/tmp/ipykernel_5348/453035365.py", line 124, in train_epoch
    predict = self.model(data)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/tmp/ipykernel_5348/1615517668.py", line 12, in forward
    output = self.predictor(encoded)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/tmp/ipykernel_5348/3528832199.py", line 105, in forward
    x = self.cnn(x)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/container.py", line 215, in forward
    input = module(input)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/modules/pooling.py", line 166, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/_jit_internal.py", line 488, in fn
    return if_false(*args, **kwargs)
  File "/home/nxhoang/Work/HPE/venv/lib/python3.8/site-packages/torch/nn/functional.py", line 791, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (59x3x20). Calculated output size: (59x0x4). Output size is too small